{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_vectorization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMhb6dCeGMi8",
        "colab_type": "text"
      },
      "source": [
        "## Atheism subreddit - check vectorization and modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miMGm5S-LfCZ",
        "colab_type": "code",
        "outputId": "6e86e71a-f549-4b23-c2b8-c04164d67259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWpAR3qnLkvY",
        "colab_type": "code",
        "outputId": "1a0de632-0c68-48e9-9990-12fa8bc8e82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!gcloud auth login"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?code_challenge=auThI0LAtQL2Vw7qYLJP9ObrghLCxUL6IhDDa-gGo4M&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
            "\n",
            "\n",
            "Enter verification code: 4/tgFLgVP6jXXHxiBk5AM6bDwkwI7ACJXnHQ5tN780R8Gave-QDX2tD-U\n",
            "\u001b[1;33mWARNING:\u001b[0m `gcloud auth login` no longer writes application default credentials.\n",
            "If you need to use ADC, see:\n",
            "  gcloud auth application-default --help\n",
            "\n",
            "You are now logged in as [galli.giuly@gmail.com].\n",
            "Your current project is [reddit-master].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZfLMXoLiaA",
        "colab_type": "code",
        "outputId": "71345eea-62eb-4622-db7a-37250b99ef26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!gcloud config set project reddit-master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijiLz9Vq4xq7",
        "colab_type": "code",
        "outputId": "170a6965-cc40-415a-ff3c-5eb0e84a583d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# !pip install wordcloud"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.3.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.17.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgLfUZmHLpdg",
        "colab_type": "code",
        "outputId": "b817c85d-c0ac-472e-8b87-c6d56ad8b133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import nltk.data\n",
        "import nltk\n",
        "import ast\n",
        "nltk.download('punkt')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import precision_score, classification_report, confusion_matrix"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDUPrnpC1Oi3",
        "colab_type": "text"
      },
      "source": [
        "Below, some intent of upload the full file and work on it.. it failed because of the dimension of the \"all subreddits\" file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKxPstNOLsQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gsutil cp gs://reddit_final_results/comments_posts_tokenized_V2.csv ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfwu_jTIkEvL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ccffa008-c829-43ce-ee6d-8dd5a51feb73"
      },
      "source": [
        "# ! head comments_posts_tokenized_V2.csv"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",subreddit,body,subreddit_id\n",
            "0,aww,doubl multipl sub approach good ya mate,3\n",
            "1,aww,2nd meatbal serious chunki english bulldog offici sir duke meatbal duke,3\n",
            "2,aww,thought,3\n",
            "3,aww,friend eat friend,3\n",
            "4,aww,mayb doctor wait heart room,3\n",
            "5,aww,tell want stay hell shave,3\n",
            "6,aww,mean,3\n",
            "7,aww,awesom,3\n",
            "8,aww,san diego poster miss,3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDj3M28xLsF3",
        "colab_type": "code",
        "outputId": "d7c78d3a-9b97-4f3a-c923-54dee45e1268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# comments_posts_tokenized_df = pd.read_csv(\"comments_posts_tokenized_V2.csv\", index_col=[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vpQRWb3Zx_K",
        "colab_type": "code",
        "outputId": "049241b6-e770-4f95-9b5c-ededd96bc192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# !gsutil cp gs://reddit_final_results/comments_posts_tokenized.csv ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_final_results/comments_posts_tokenized.csv...\n",
            "/ [1 files][  1.7 GiB/  1.7 GiB]   83.4 MiB/s                                   \n",
            "Operation completed over 1 objects/1.7 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIlavTfzpM5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b8327bce-c469-4eb9-9717-f3e38cf2cb3d"
      },
      "source": [
        "# comments_posts_tokenized_df = pd.read_csv(\"comments_posts_tokenized.csv\", index_col=[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un7s4wXMjIkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c6a667a-9f41-4730-8c91-07f562ed79e0"
      },
      "source": [
        "# Asfer a bad vectorization I've looked into the column body: the type is string and the vectorization process didn't work as I needed\n",
        "\n",
        "# type(comments_posts_tokenized_df['body'].iloc[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yCeLudJhk40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's convert the column body into a list\n",
        "# trying on a sample\n",
        "# sample = comments_posts_tokenized_df.sample(20)\n",
        "# sample['body'] = sample['body'].map(lambda x: ast.literal_eval(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPm1IrqzjDR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0569824c-7385-471c-d379-3d079e2625b3"
      },
      "source": [
        "# it works\n",
        "\n",
        "# type(sample['body'].iloc[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbHKrRhoZ1Ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's do it in our original df\n",
        "\n",
        " #comments_posts_tokenized_df['body'] = comments_posts_tokenized_df['body'].map(lambda x: ast.literal_eval(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e11B8nnk2Nlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b52a6514-35e6-4795-c2fa-235408c61af9"
      },
      "source": [
        "# !gsutil cp gs://reddit_final_results/comments_posts_tokenized_df_gzip.pkl ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_final_results/comments_posts_tokenized_df_gzip.pkl...\n",
            "/ [1 files][488.7 MiB/488.7 MiB]                                                \n",
            "Operation completed over 1 objects/488.7 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO0eXWQ91uf8",
        "colab_type": "text"
      },
      "source": [
        "From here I changed the strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tly-_BRmdnPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subreddits = ['aww', 'nba', 'movies', 'todayilearned', 'IAmA', 'Fitness', 'worldnews', 'technology', 'europe', 'politics', 'atheism','science', 'funny', 'gaming']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwgBfc9Ddm-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "929ccd34-cdbb-4e50-acb7-0c1c2d326b26"
      },
      "source": [
        "for subreddit in subreddits:\n",
        "    !gsutil cp gs://reddit_final_results/comments_posts_{subreddit}.pkl .\n",
        "    print(\"comments_posts_\" + subreddit + \".pkl downloaded\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://reddit_final_results/comments_posts_aww.pkl...\n",
            "\\ [1 files][ 63.8 MiB/ 63.8 MiB]                                                \n",
            "Operation completed over 1 objects/63.8 MiB.                                     \n",
            "comments_posts_aww.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_nba.pkl...\n",
            "\\ [1 files][ 88.3 MiB/ 88.3 MiB]                                                \n",
            "Operation completed over 1 objects/88.3 MiB.                                     \n",
            "comments_posts_nba.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_movies.pkl...\n",
            "\\ [1 files][103.2 MiB/103.2 MiB]                                                \n",
            "Operation completed over 1 objects/103.2 MiB.                                    \n",
            "comments_posts_movies.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_todayilearned.pkl...\n",
            "| [1 files][101.1 MiB/101.1 MiB]                                                \n",
            "Operation completed over 1 objects/101.1 MiB.                                    \n",
            "comments_posts_todayilearned.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_IAmA.pkl...\n",
            "\\ [1 files][132.8 MiB/132.8 MiB]                                                \n",
            "Operation completed over 1 objects/132.8 MiB.                                    \n",
            "comments_posts_IAmA.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_Fitness.pkl...\n",
            "| [1 files][144.0 MiB/144.0 MiB]                                                \n",
            "Operation completed over 1 objects/144.0 MiB.                                    \n",
            "comments_posts_Fitness.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_worldnews.pkl...\n",
            "\\ [1 files][134.8 MiB/134.8 MiB]                                                \n",
            "Operation completed over 1 objects/134.8 MiB.                                    \n",
            "comments_posts_worldnews.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_technology.pkl...\n",
            "\\ [1 files][136.2 MiB/136.2 MiB]                                                \n",
            "Operation completed over 1 objects/136.2 MiB.                                    \n",
            "comments_posts_technology.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_europe.pkl...\n",
            "\\ [1 files][128.4 MiB/128.4 MiB]                                                \n",
            "Operation completed over 1 objects/128.4 MiB.                                    \n",
            "comments_posts_europe.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_politics.pkl...\n",
            "\\ [1 files][118.7 MiB/118.7 MiB]                                                \n",
            "Operation completed over 1 objects/118.7 MiB.                                    \n",
            "comments_posts_politics.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_atheism.pkl...\n",
            "/ [1 files][144.0 MiB/144.0 MiB]                                                \n",
            "Operation completed over 1 objects/144.0 MiB.                                    \n",
            "comments_posts_atheism.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_science.pkl...\n",
            "\\ [1 files][147.5 MiB/147.5 MiB]                                                \n",
            "Operation completed over 1 objects/147.5 MiB.                                    \n",
            "comments_posts_science.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_funny.pkl...\n",
            "\\ [1 files][ 69.3 MiB/ 69.3 MiB]                                                \n",
            "Operation completed over 1 objects/69.3 MiB.                                     \n",
            "comments_posts_funny.pkl downloaded\n",
            "Copying gs://reddit_final_results/comments_posts_gaming.pkl...\n",
            "- [1 files][ 79.4 MiB/ 79.4 MiB]                                                \n",
            "Operation completed over 1 objects/79.4 MiB.                                     \n",
            "comments_posts_gaming.pkl downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAInIyvZfsOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "697a23b2-c885-4c97-9fad-f1c69ed8c2f0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\t\t    comments_posts_movies.pkl\n",
            "comments_posts_atheism.pkl  comments_posts_nba.pkl\n",
            "comments_posts_aww.pkl\t    comments_posts_politics.pkl\n",
            "comments_posts_europe.pkl   comments_posts_science.pkl\n",
            "comments_posts_Fitness.pkl  comments_posts_technology.pkl\n",
            "comments_posts_funny.pkl    comments_posts_todayilearned.pkl\n",
            "comments_posts_gaming.pkl   comments_posts_worldnews.pkl\n",
            "comments_posts_IAmA.pkl     sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qaDW9-NN-sk",
        "colab_type": "text"
      },
      "source": [
        "I decided to try my validations and models on one subreddit `atheism` just to check fix errors and check if I'm following the corrects steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40SKCHM9gsqq",
        "colab_type": "text"
      },
      "source": [
        "### comments_posts_atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0-XHphh2a2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_atheism = pd.read_pickle(\"/content/comments_posts_atheism.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx8LGw1XN8en",
        "colab_type": "code",
        "outputId": "85272392-b977-45c8-8d3c-687239454d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_atheism.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0.1', 'subreddit', 'body', 'subreddit_id'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0wX8SHc3lY-",
        "colab_type": "code",
        "outputId": "1945a61a-f94a-442f-b5eb-c27c344e43c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "df_atheism.head(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>subreddit_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>88650</th>\n",
              "      <td>88650</td>\n",
              "      <td>atheism</td>\n",
              "      <td>[argu, deep, human, except, thing, defianc, idea]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88651</th>\n",
              "      <td>88651</td>\n",
              "      <td>atheism</td>\n",
              "      <td>[differ, harri, potter, bibl, coupl, billion, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88652</th>\n",
              "      <td>88652</td>\n",
              "      <td>atheism</td>\n",
              "      <td>[explain, argument]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0.1  ... subreddit_id\n",
              "88650         88650  ...            2\n",
              "88651         88651  ...            2\n",
              "88652         88652  ...            2\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCNnwmuM6BET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20ed580c-361a-46a0-b504-a0bc0c85f2c9"
      },
      "source": [
        "type(df_atheism['body'].iloc[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyUTWHVQ6ICr",
        "colab_type": "text"
      },
      "source": [
        "Let's rock!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHBjxjBOMe3",
        "colab_type": "text"
      },
      "source": [
        "## Train, validation, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBqDC9FfOMwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90cf3cf2-e10f-484e-aa0d-7ab5100d3881"
      },
      "source": [
        "subreddits = df_atheism['subreddit'].unique()\n",
        "print(subreddits)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['atheism']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFZ2U9bAOL9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_atheism['body']\n",
        "y = df_atheism['subreddit_id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KiNJKmZOcbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definint a fucntion that slit the dataset into three subsets: train, val and test\n",
        "def train_dev_test_split(X, y):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42, stratify=y_val)\n",
        "    return dict(X_train=X_train, \n",
        "                X_val=X_val, \n",
        "                X_test=X_test, \n",
        "                y_train=y_train, \n",
        "                y_val=y_val, \n",
        "                y_test=y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLMr0Kn-OjDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_atheism_split = train_dev_test_split(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5IPcab0Oi3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4974306a-7b58-499a-ad8b-b04976091f74"
      },
      "source": [
        "df_atheism_split.keys()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['X_train', 'X_val', 'X_test', 'y_train', 'y_val', 'y_test'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq2cMgA1Qkge",
        "colab_type": "text"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUc2E-T-hVxh",
        "colab_type": "text"
      },
      "source": [
        "#### FTIDF vectorization - atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Lal6OXhat9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e75d27b-e9ec-4789-cdde-b7e7f24c9918"
      },
      "source": [
        "%%time\n",
        "tfidf=TfidfVectorizer()\n",
        "tfidf_atheism= tfidf.fit_transform(df_atheism['body'].astype(str))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19.9 s, sys: 296 ms, total: 20.2 s\n",
            "Wall time: 20.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTIgFkA_harc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "247bbe4a-45a4-4d2d-bb59-dbee728f58c6"
      },
      "source": [
        "tfidf.get_feature_names()[::-1]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zzzzzzzzzzzzzz',\n",
              " 'zzzzzzzzzzz',\n",
              " 'zzzzzzzzxzzzzzzzzz',\n",
              " 'zzzzzz',\n",
              " 'zzz',\n",
              " 'zzshzzshhhzzsshhhhi',\n",
              " 'zzrt',\n",
              " 'zz9',\n",
              " 'zz',\n",
              " 'zyx',\n",
              " 'zyrgfrh',\n",
              " 'zyprexa',\n",
              " 'zyklonb',\n",
              " 'zyklon',\n",
              " 'zyhem',\n",
              " 'zyhe',\n",
              " 'zygoteyou',\n",
              " 'zygotethat',\n",
              " 'zygotesof',\n",
              " 'zygotesin',\n",
              " 'zygoteshowev',\n",
              " 'zygotesgti',\n",
              " 'zygotesgtalso',\n",
              " 'zygotesfetus',\n",
              " 'zygotesembryosedit',\n",
              " 'zygotesblastula',\n",
              " 'zygoteor',\n",
              " 'zygotenobodi',\n",
              " 'zygoteit',\n",
              " 'zygotei',\n",
              " 'zygotefoetus',\n",
              " 'zygotefetusembryoetc',\n",
              " 'zygotefetus',\n",
              " 'zygoteembryofetusbabi',\n",
              " 'zygoteembryofetus',\n",
              " 'zygoteembryo',\n",
              " 'zygotecreampi',\n",
              " 'zygotebut',\n",
              " 'zygotea',\n",
              " 'zygote',\n",
              " 'zygot',\n",
              " 'zyclon',\n",
              " 'zy',\n",
              " 'zxcvb94105',\n",
              " 'zx',\n",
              " 'zwoodfin03it',\n",
              " 'zwischen',\n",
              " 'zwinglist',\n",
              " 'zwing',\n",
              " 'zwicker',\n",
              " 'zwhat',\n",
              " 'zwell',\n",
              " 'zweiundvierzig',\n",
              " 'zweihand',\n",
              " 'zwei',\n",
              " 'zweebil',\n",
              " 'zweckbindung',\n",
              " 'zwart',\n",
              " 'zwaanof',\n",
              " 'zwaan',\n",
              " 'zvp',\n",
              " 'zvolili',\n",
              " 'zvk',\n",
              " 'zvanth',\n",
              " 'zuul',\n",
              " 'zutreten',\n",
              " 'zustnd',\n",
              " 'zustimmen',\n",
              " 'zuss',\n",
              " 'zus',\n",
              " 'zurvan',\n",
              " 'zurita',\n",
              " 'zurishaddaigt',\n",
              " 'zurich',\n",
              " 'zurg',\n",
              " 'zurentecurtisit',\n",
              " 'zur',\n",
              " 'zupernam',\n",
              " 'zuo',\n",
              " 'zunless',\n",
              " 'zune',\n",
              " 'zunachst',\n",
              " 'zumwalt',\n",
              " 'zumdahl',\n",
              " 'zumal',\n",
              " 'zuma',\n",
              " 'zum',\n",
              " 'zuluz',\n",
              " 'zulus',\n",
              " 'zulu',\n",
              " 'zula',\n",
              " 'zukunft',\n",
              " 'zukorfirst',\n",
              " 'zuk',\n",
              " 'zuilen',\n",
              " 'zuil',\n",
              " 'zuhr',\n",
              " 'zuhdi',\n",
              " 'zuerst',\n",
              " 'zue',\n",
              " 'zuckerman',\n",
              " 'zuckerburg',\n",
              " 'zuckerbergmost',\n",
              " 'zuckerberglik',\n",
              " 'zuckerberg',\n",
              " 'zucker',\n",
              " 'zuck',\n",
              " 'zuchetti',\n",
              " 'zucchinibergit',\n",
              " 'zucchini',\n",
              " 'zucc',\n",
              " 'zubrin',\n",
              " 'zubik',\n",
              " 'zubair',\n",
              " 'zub',\n",
              " 'zuargt',\n",
              " 'zu',\n",
              " 'zts',\n",
              " 'ztl',\n",
              " 'zthen',\n",
              " 'zthe',\n",
              " 'zte',\n",
              " 'ztart',\n",
              " 'zsuper',\n",
              " 'zso',\n",
              " 'zs2note',\n",
              " 'zs',\n",
              " 'zrich',\n",
              " 'zr1',\n",
              " 'zpg',\n",
              " 'zpac',\n",
              " 'zous',\n",
              " 'zound',\n",
              " 'zoti',\n",
              " 'zothyoggsaron',\n",
              " 'zoster',\n",
              " 'zoso525it',\n",
              " 'zoser',\n",
              " 'zos',\n",
              " 'zorroast',\n",
              " 'zorro',\n",
              " 'zorp',\n",
              " 'zorostrian',\n",
              " 'zoroastrianther',\n",
              " 'zoroastriansnowruz',\n",
              " 'zoroastriansalso',\n",
              " 'zoroastriansalkhwarizmi',\n",
              " 'zoroastrianist',\n",
              " 'zoroastrianismzoroastrian',\n",
              " 'zoroastrianismyeah',\n",
              " 'zoroastrianismit',\n",
              " 'zoroastrianismfurthermor',\n",
              " 'zoroastrianbecaus',\n",
              " 'zoroastrian45',\n",
              " 'zoroastrian',\n",
              " 'zoroastr',\n",
              " 'zoroastianist',\n",
              " 'zoroasterian',\n",
              " 'zoroast',\n",
              " 'zorkox',\n",
              " 'zork',\n",
              " 'zorgonian',\n",
              " 'zorgonan',\n",
              " 'zorgon',\n",
              " 'zorg',\n",
              " 'zoreon1',\n",
              " 'zorbo',\n",
              " 'zorba',\n",
              " 'zorastrian',\n",
              " 'zoraost',\n",
              " 'zoramit',\n",
              " 'zorach',\n",
              " 'zophar',\n",
              " 'zoowhat',\n",
              " 'zootopia',\n",
              " 'zoosno',\n",
              " 'zoorough',\n",
              " 'zooroastin',\n",
              " 'zooplankton',\n",
              " 'zoophiliac',\n",
              " 'zoophilia',\n",
              " 'zoophil',\n",
              " 'zoop',\n",
              " 'zoonomia',\n",
              " 'zoonivers',\n",
              " 'zoonatur',\n",
              " 'zoomzoom202thankyou',\n",
              " 'zoomout',\n",
              " 'zoomi',\n",
              " 'zoomer',\n",
              " 'zoomedout',\n",
              " 'zoom',\n",
              " 'zoologyth',\n",
              " 'zoologist',\n",
              " 'zoolog',\n",
              " 'zooland',\n",
              " 'zool',\n",
              " 'zookeep',\n",
              " 'zoojirushi',\n",
              " 'zooey',\n",
              " 'zoodl',\n",
              " 'zoocieti',\n",
              " 'zoocagegtgt',\n",
              " 'zoo4',\n",
              " 'zoo',\n",
              " 'zonk',\n",
              " 'zongtang',\n",
              " 'zoneyoung',\n",
              " 'zoneyou',\n",
              " 'zoneunmap',\n",
              " 'zonethank',\n",
              " 'zoneso',\n",
              " 'zonesnak',\n",
              " 'zonesit',\n",
              " 'zoneshey',\n",
              " 'zonesand',\n",
              " 'zonesach',\n",
              " 'zones2',\n",
              " 'zonenod',\n",
              " 'zonemi',\n",
              " 'zonei',\n",
              " 'zonegti',\n",
              " 'zonefre',\n",
              " 'zonechristian',\n",
              " 'zoneand',\n",
              " 'zonea',\n",
              " 'zone',\n",
              " 'zondervan',\n",
              " 'zonbi',\n",
              " 'zonald',\n",
              " 'zonah',\n",
              " 'zona',\n",
              " 'zon',\n",
              " 'zomgzlolbbq',\n",
              " 'zomg',\n",
              " 'zombit',\n",
              " 'zombigrizzit',\n",
              " 'zombifi',\n",
              " 'zombif',\n",
              " 'zombiewhatev',\n",
              " 'zombietoo',\n",
              " 'zombieto',\n",
              " 'zombiether',\n",
              " 'zombiethem',\n",
              " 'zombiesyou',\n",
              " 'zombieswoah',\n",
              " 'zombieswizard',\n",
              " 'zombieswhich',\n",
              " 'zombieswhi',\n",
              " 'zombiesurviv',\n",
              " 'zombiesimpson',\n",
              " 'zombiesdemon',\n",
              " 'zombiepriest',\n",
              " 'zombiemovi',\n",
              " 'zombieism',\n",
              " 'zombieffit',\n",
              " 'zombi',\n",
              " 'zombeez',\n",
              " 'zolton',\n",
              " 'zoltan99',\n",
              " 'zoltan',\n",
              " 'zolpidem',\n",
              " 'zoloft',\n",
              " 'zoidberg',\n",
              " 'zohar',\n",
              " 'zoftig',\n",
              " 'zoey',\n",
              " 'zoellner',\n",
              " 'zoe',\n",
              " 'zodiolog',\n",
              " 'zodiacth',\n",
              " 'zodiacsynchron',\n",
              " 'zodiacon',\n",
              " 'zodiacnon',\n",
              " 'zodiaci',\n",
              " 'zodiac',\n",
              " 'zod',\n",
              " 'zobvious',\n",
              " 'zobject',\n",
              " 'zoastrian',\n",
              " 'zoarand',\n",
              " 'zoar',\n",
              " 'zo',\n",
              " 'zno',\n",
              " 'znation',\n",
              " 'znanj',\n",
              " 'znam',\n",
              " 'znakzamisli',\n",
              " 'znaci',\n",
              " 'zna',\n",
              " 'zn',\n",
              " 'zmilleni',\n",
              " 'zmijewski',\n",
              " 'zlotonewscom',\n",
              " 'zlotonew',\n",
              " 'zloba',\n",
              " 'zlo',\n",
              " 'zli',\n",
              " 'zlatan',\n",
              " 'zla',\n",
              " 'zj',\n",
              " 'zizek',\n",
              " 'zizdidnothingwrongit',\n",
              " 'ziyarid',\n",
              " 'zivotno',\n",
              " 'zivot',\n",
              " 'zivil',\n",
              " 'zivi',\n",
              " 'ziusudraatrahasisnoah',\n",
              " 'ziusudra',\n",
              " 'ziu',\n",
              " 'zitst',\n",
              " 'ziti',\n",
              " 'zit',\n",
              " 'zis5it',\n",
              " 'zis',\n",
              " 'zirwa',\n",
              " 'zirsgth',\n",
              " 'zirsdon',\n",
              " 'zirconuranium',\n",
              " 'zirconia',\n",
              " 'zircon',\n",
              " 'zirakzigil',\n",
              " 'zir',\n",
              " 'zipziltchnahdah',\n",
              " 'ziprecruita',\n",
              " 'ziprecruit',\n",
              " 'zippothus',\n",
              " 'zipporah',\n",
              " 'zippo',\n",
              " 'zipper',\n",
              " 'ziploc',\n",
              " 'ziplin',\n",
              " 'zipfwiw',\n",
              " 'zipf',\n",
              " 'zipcod',\n",
              " 'zip',\n",
              " 'ziophil',\n",
              " 'ziony',\n",
              " 'ziontologist',\n",
              " 'ziontolog',\n",
              " 'zionsvill',\n",
              " 'zionistsisrael',\n",
              " 'zionistjew',\n",
              " 'zionistdecad',\n",
              " 'zionist',\n",
              " 'zionismth',\n",
              " 'zionismok',\n",
              " 'zionismevangelic',\n",
              " 'zionismclown',\n",
              " 'zionismchristian',\n",
              " 'zionismat',\n",
              " 'zionismanoth',\n",
              " 'zionism',\n",
              " 'zionisaliveit',\n",
              " 'zionin',\n",
              " 'zioni',\n",
              " 'zion',\n",
              " 'ziograffiatothankyou',\n",
              " 'ziofriend',\n",
              " 'zinzendorf',\n",
              " 'zinn',\n",
              " 'zink',\n",
              " 'zinj',\n",
              " 'zingl',\n",
              " 'zingi',\n",
              " 'zinggood',\n",
              " 'zingerbrg',\n",
              " 'zinger',\n",
              " 'zingen',\n",
              " 'zing',\n",
              " 'zine',\n",
              " 'zindlerampx200b',\n",
              " 'zindler',\n",
              " 'zindel',\n",
              " 'zindabaadhop',\n",
              " 'zinc',\n",
              " 'zina',\n",
              " 'zin',\n",
              " 'zimri',\n",
              " 'zimmi',\n",
              " 'zimmermann',\n",
              " 'zimmermanatheist',\n",
              " 'zimmerman',\n",
              " 'zimmer',\n",
              " 'zimmattackit',\n",
              " 'zimbabweterrorist',\n",
              " 'zimbabw',\n",
              " 'zim',\n",
              " 'ziltch',\n",
              " 'zillow',\n",
              " 'zillionth',\n",
              " 'zillion1',\n",
              " 'zillion',\n",
              " 'zillah',\n",
              " 'zildrohar',\n",
              " 'zilchyour',\n",
              " 'zilchwhich',\n",
              " 'zilch',\n",
              " 'zikr',\n",
              " 'zikh',\n",
              " 'zika',\n",
              " 'zijn',\n",
              " 'zii',\n",
              " 'zigzag',\n",
              " 'ziggyzoo',\n",
              " 'zigguratsstep',\n",
              " 'zigguratss',\n",
              " 'ziggurat',\n",
              " 'ziggourat',\n",
              " 'ziggiti',\n",
              " 'ziggi',\n",
              " 'zig',\n",
              " 'ziffmin',\n",
              " 'ziezirzirszirselfzhezhirzhirszhirselfzehirhirshirselfhirhirhirshirselfsiesiersierssierselfzedzedzedszedselfzedzedzeirzedselfcecircirscirselfcocoscoscoselfvevisvirverselfvevemvirvemselfjeejemjeirjemselfjhejherjherjherselfleelimlislimselfkyekyrkynekyrselfkiekirkir',\n",
              " 'ziezir',\n",
              " 'zielsgelukkig',\n",
              " 'zie',\n",
              " 'zibbub',\n",
              " 'zibbleblorf',\n",
              " 'ziaulhaq',\n",
              " 'zi',\n",
              " 'zhuster',\n",
              " 'zhul',\n",
              " 'zhuangzi',\n",
              " 'zhou',\n",
              " 'zhonghua',\n",
              " 'zhomeland',\n",
              " 'zhivago',\n",
              " 'zhimou',\n",
              " 'zhihu',\n",
              " 'zhi',\n",
              " 'zhejiang',\n",
              " 'zhe',\n",
              " 'zhao',\n",
              " 'zgrade',\n",
              " 'zgener',\n",
              " 'zezali',\n",
              " 'zeynelian',\n",
              " 'zeyneb',\n",
              " 'zeyd',\n",
              " 'zevon',\n",
              " 'zevit',\n",
              " 'zeveri',\n",
              " 'zevach',\n",
              " 'zeusyour',\n",
              " 'zeusyou',\n",
              " 'zeusthes',\n",
              " 'zeusthen',\n",
              " 'zeusthem',\n",
              " 'zeusthat',\n",
              " 'zeuss',\n",
              " 'zeusp',\n",
              " 'zeusodinlokietc',\n",
              " 'zeusodinapollo',\n",
              " 'zeusnowel',\n",
              " 'zeusno',\n",
              " 'zeusless',\n",
              " 'zeusit',\n",
              " 'zeusin',\n",
              " 'zeusif',\n",
              " 'zeusi',\n",
              " 'zeush',\n",
              " 'zeusgt',\n",
              " 'zeusfre',\n",
              " 'zeusedit',\n",
              " 'zeusdo',\n",
              " 'zeusatheist',\n",
              " 'zeusand',\n",
              " 'zeusanci',\n",
              " 'zeusammon',\n",
              " 'zeusallahindrakrishnawhatev',\n",
              " 'zeusalien',\n",
              " 'zeus6',\n",
              " 'zeus',\n",
              " 'zeugma25it',\n",
              " 'zetz',\n",
              " 'zettasecond',\n",
              " 'zetian',\n",
              " 'zetgeist',\n",
              " 'zetet',\n",
              " 'zetassinaloa',\n",
              " 'zeta',\n",
              " 'zesus',\n",
              " 'zest',\n",
              " 'zervo',\n",
              " 'zerozeronow',\n",
              " 'zerozeroamen',\n",
              " 'zerozero',\n",
              " 'zeroyou',\n",
              " 'zeroy',\n",
              " 'zerowith',\n",
              " 'zerowhich',\n",
              " 'zerowhat',\n",
              " 'zerowe',\n",
              " 'zerowast',\n",
              " 'zerow',\n",
              " 'zerovacuum',\n",
              " 'zerotwo',\n",
              " 'zeroturn',\n",
              " 'zerotoler',\n",
              " 'zerotldr',\n",
              " 'zerothi',\n",
              " 'zerothey',\n",
              " 'zerother',\n",
              " 'zerothat',\n",
              " 'zeroth',\n",
              " 'zerosun',\n",
              " 'zerosum',\n",
              " 'zerostandard',\n",
              " 'zerosourc',\n",
              " 'zeroso',\n",
              " 'zeroresearch',\n",
              " 'zeror',\n",
              " 'zeropointinfinit',\n",
              " 'zeropoint',\n",
              " 'zeroplus',\n",
              " 'zeropenn',\n",
              " 'zeroon',\n",
              " 'zeronumb',\n",
              " 'zeronorm',\n",
              " 'zeronop',\n",
              " 'zerol',\n",
              " 'zerojust',\n",
              " 'zerojim',\n",
              " 'zeroit',\n",
              " 'zeroinfin',\n",
              " 'zeroif',\n",
              " 'zeroi',\n",
              " 'zerohowev',\n",
              " 'zerohesh',\n",
              " 'zeroh',\n",
              " 'zerogtnon',\n",
              " 'zerogti',\n",
              " 'zerogt',\n",
              " 'zerog',\n",
              " 'zerofuck',\n",
              " 'zerofor',\n",
              " 'zeroevidencegt',\n",
              " 'zeroeventu',\n",
              " 'zeroeson',\n",
              " 'zeroenergi',\n",
              " 'zeroedit',\n",
              " 'zerodo',\n",
              " 'zerodimension',\n",
              " 'zerodespit',\n",
              " 'zeroday',\n",
              " 'zerocom',\n",
              " 'zerocli',\n",
              " 'zeroapproach',\n",
              " 'zeroand',\n",
              " 'zeroan',\n",
              " 'zeroalthough',\n",
              " 'zeroactu',\n",
              " 'zeroa',\n",
              " 'zero3',\n",
              " 'zero2',\n",
              " 'zero',\n",
              " 'zergl',\n",
              " 'zerg',\n",
              " 'zerbeeeeepal',\n",
              " 'zera',\n",
              " 'zer',\n",
              " 'zeppo',\n",
              " 'zepplin',\n",
              " 'zeppelin',\n",
              " 'zepp',\n",
              " 'zephyr',\n",
              " 'zephath',\n",
              " 'zeph',\n",
              " 'zep37',\n",
              " 'zep',\n",
              " 'zenyatta',\n",
              " 'zenu',\n",
              " 'zentrumsparteien',\n",
              " 'zentrum',\n",
              " 'zenreind',\n",
              " 'zenophobia',\n",
              " 'zenon',\n",
              " 'zenom',\n",
              " 'zenobunk',\n",
              " 'zeno',\n",
              " 'zenniopticalcom',\n",
              " 'zenlik',\n",
              " 'zenithnadir',\n",
              " 'zenith',\n",
              " 'zenit',\n",
              " 'zenim',\n",
              " 'zeng',\n",
              " 'zener',\n",
              " 'zeneca',\n",
              " 'zene',\n",
              " 'zenduri',\n",
              " 'zend',\n",
              " 'zenana',\n",
              " 'zen',\n",
              " 'zemzem',\n",
              " 'zemdlec',\n",
              " 'zeman',\n",
              " 'zelph',\n",
              " 'zelotri',\n",
              " 'zelotcan',\n",
              " 'zelot',\n",
              " 'zelim',\n",
              " 'zeligi',\n",
              " 'zelet',\n",
              " 'zeldin',\n",
              " 'zeldabas',\n",
              " 'zelda',\n",
              " 'zelazni',\n",
              " 'zeki',\n",
              " 'zeke',\n",
              " 'zeitung',\n",
              " 'zeitpunkt',\n",
              " 'zeitoun',\n",
              " 'zeitgiest',\n",
              " 'zeitgeistafaik',\n",
              " 'zeitgeist5th',\n",
              " 'zeitgeist',\n",
              " 'zeitgeisorri',\n",
              " 'zeiten',\n",
              " 'zeiss',\n",
              " 'zeidokkuthankyou',\n",
              " 'zehn',\n",
              " 'zehir',\n",
              " 'zeg',\n",
              " 'zeeshan',\n",
              " 'zeesh',\n",
              " 'zeenewsindiacom',\n",
              " 'zeemei',\n",
              " 'zeeland',\n",
              " 'zeeeeeeeeeeeeeerooooooooooo',\n",
              " 'zeeand',\n",
              " 'zee',\n",
              " 'zedz',\n",
              " 'zedongmillion',\n",
              " 'zedongmao',\n",
              " 'zedongcommunist',\n",
              " 'zedong',\n",
              " 'zedofacalhao',\n",
              " 'zedmor',\n",
              " 'zedex786it',\n",
              " 'zedekiah',\n",
              " 'zedekia',\n",
              " 'zeddemoreif',\n",
              " 'zeddemor',\n",
              " 'zed',\n",
              " 'zechariah',\n",
              " 'zecharia',\n",
              " 'zech',\n",
              " 'zeccariah',\n",
              " 'zebulungt',\n",
              " 'zebulun12000',\n",
              " 'zebulun',\n",
              " 'zebulon',\n",
              " 'zebul',\n",
              " 'zebrayour',\n",
              " 'zebratauricorn',\n",
              " 'zebrasth',\n",
              " 'zebrasi',\n",
              " 'zebra',\n",
              " 'zeboim',\n",
              " 'zeboiim',\n",
              " 'zebede',\n",
              " 'zebadiah',\n",
              " 'zebade',\n",
              " 'zeba',\n",
              " 'zealyou',\n",
              " 'zealthi',\n",
              " 'zealthat',\n",
              " 'zealousyour',\n",
              " 'zealousprev',\n",
              " 'zealousif',\n",
              " 'zealousedit',\n",
              " 'zealous',\n",
              " 'zealouli',\n",
              " 'zealotword',\n",
              " 'zealotsyeah',\n",
              " 'zealotswho',\n",
              " 'zealotswhi',\n",
              " 'zealotswhen',\n",
              " 'zealotswellassum',\n",
              " 'zealotsus',\n",
              " 'zealotsthat',\n",
              " 'zealotsth',\n",
              " 'zealotsso',\n",
              " 'zealotso',\n",
              " 'zealotsit',\n",
              " 'zealotsif',\n",
              " 'zealotsidiot',\n",
              " 'zealotsh',\n",
              " 'zealotsgt',\n",
              " 'zealotsgay',\n",
              " 'zealotsfirst',\n",
              " 'zealotsand',\n",
              " 'zealotsampnbspgr',\n",
              " 'zealotrynot',\n",
              " 'zealotrylik',\n",
              " 'zealotryjust',\n",
              " 'zealotri',\n",
              " 'zealotreligion',\n",
              " 'zealotmind',\n",
              " 'zealotmak',\n",
              " 'zealotjim',\n",
              " 'zealoti',\n",
              " 'zealotflavour',\n",
              " 'zealotbigot',\n",
              " 'zealotand',\n",
              " 'zealot',\n",
              " 'zealesi',\n",
              " 'zealengland',\n",
              " 'zealanf',\n",
              " 'zealandw',\n",
              " 'zealandthi',\n",
              " 'zealandso',\n",
              " 'zealandruntim',\n",
              " 'zealanditalyswedensouth',\n",
              " 'zealandirreligion',\n",
              " 'zealandapologist',\n",
              " 'zealand389702017thes',\n",
              " 'zealand3',\n",
              " 'zealand',\n",
              " 'zeal',\n",
              " 'ze',\n",
              " 'zdrowi',\n",
              " 'zdravo',\n",
              " 'zcorrel',\n",
              " 'zcmi',\n",
              " 'zchart',\n",
              " 'zbornak',\n",
              " 'zbog',\n",
              " 'zbell',\n",
              " 'zazzl',\n",
              " 'zazz',\n",
              " 'zazen',\n",
              " 'zazazi',\n",
              " 'zazanzo',\n",
              " 'zaza',\n",
              " 'zaynnow',\n",
              " 'zaynab',\n",
              " 'zayn',\n",
              " 'zayd',\n",
              " 'zaxbi',\n",
              " 'zaxariya',\n",
              " 'zawahiri',\n",
              " 'zavist',\n",
              " 'zauzimati',\n",
              " 'zauriel',\n",
              " 'zatryufor',\n",
              " 'zato',\n",
              " 'zatheria',\n",
              " 'zaterdag',\n",
              " 'zatannazataradr',\n",
              " 'zatann',\n",
              " 'zasto',\n",
              " 'zarsthustra',\n",
              " 'zarquod',\n",
              " 'zarploptark',\n",
              " 'zarownybecaus',\n",
              " 'zarowni',\n",
              " 'zarniwoop',\n",
              " 'zaria',\n",
              " 'zari31',\n",
              " 'zarephathhoreb',\n",
              " 'zarephath',\n",
              " 'zardoz',\n",
              " 'zarbon',\n",
              " 'zaratustrian',\n",
              " 'zaratustra',\n",
              " 'zarathustra',\n",
              " 'zarathosht',\n",
              " 'zarar',\n",
              " 'zarah',\n",
              " 'zara',\n",
              " 'zar',\n",
              " 'zaqqum',\n",
              " 'zaprud',\n",
              " 'zapper',\n",
              " 'zappadumb',\n",
              " 'zappa',\n",
              " 'zapp',\n",
              " 'zapotec',\n",
              " 'zaphon',\n",
              " 'zaphod',\n",
              " 'zapateroyou',\n",
              " 'zapatero',\n",
              " 'zapat',\n",
              " 'zaparth',\n",
              " 'zap',\n",
              " 'zao',\n",
              " 'zanzibari',\n",
              " 'zanzibar',\n",
              " 'zanu',\n",
              " 'zanti',\n",
              " 'zantheus',\n",
              " 'zanskar',\n",
              " 'zannos123it',\n",
              " 'zanj',\n",
              " 'zani',\n",
              " 'zangheif',\n",
              " 'zangaridioces',\n",
              " 'zane173it',\n",
              " 'zane',\n",
              " 'zandiy',\n",
              " 'zandi',\n",
              " 'zand',\n",
              " 'zanardelli',\n",
              " 'zanadiq',\n",
              " 'zana',\n",
              " 'zan',\n",
              " 'zamzam',\n",
              " 'zamorakian',\n",
              " 'zamolxs',\n",
              " 'zammi',\n",
              " 'zamisl',\n",
              " 'zamindar',\n",
              " 'zambian',\n",
              " 'zambiainterest',\n",
              " 'zambia',\n",
              " 'zamasu',\n",
              " 'zaman',\n",
              " 'zama',\n",
              " 'zalmoxi',\n",
              " 'zalman',\n",
              " 'zale',\n",
              " 'zaku',\n",
              " 'zakljucio',\n",
              " 'zakir',\n",
              " 'zakharov',\n",
              " 'zakateduc',\n",
              " 'zakatar',\n",
              " 'zakat',\n",
              " 'zakariya',\n",
              " 'zakaria',\n",
              " 'zakah',\n",
              " 'zakaat',\n",
              " 'zakaah',\n",
              " 'zak',\n",
              " 'zaius',\n",
              " 'zaith',\n",
              " 'zairian',\n",
              " 'zairegtrobertson',\n",
              " 'zair',\n",
              " 'zainat',\n",
              " 'zain',\n",
              " 'zaik',\n",
              " 'zaid',\n",
              " 'zahnyeah',\n",
              " 'zahlten',\n",
              " 'zahl',\n",
              " 'zahira',\n",
              " 'zahal',\n",
              " 'zah',\n",
              " 'zagreb',\n",
              " 'zag',\n",
              " 'zaftig',\n",
              " 'zafaron',\n",
              " 'zadvyda',\n",
              " 'zadocfishgt',\n",
              " 'zaddi',\n",
              " 'zact',\n",
              " 'zack',\n",
              " 'zacharybesid',\n",
              " 'zachariass',\n",
              " 'zachariaslast',\n",
              " 'zachariah',\n",
              " 'zacharia',\n",
              " 'zachari',\n",
              " 'zachar20',\n",
              " 'zachar',\n",
              " 'zach',\n",
              " 'zacat',\n",
              " 'zac',\n",
              " 'zabuja',\n",
              " 'zabrijao',\n",
              " 'zabranjeno',\n",
              " 'zabowski',\n",
              " 'zaber',\n",
              " 'zabba',\n",
              " 'zaaqq',\n",
              " 'za463092it',\n",
              " 'za',\n",
              " 'z71',\n",
              " 'z309p002',\n",
              " 'z303p002',\n",
              " 'z298p002',\n",
              " 'z2001present',\n",
              " 'z0diark88it',\n",
              " 'z0',\n",
              " 'yzf',\n",
              " 'yz',\n",
              " 'yyyyyyik',\n",
              " 'yyyyyep',\n",
              " 'yyyymmdd',\n",
              " 'yyyuck',\n",
              " 'yyyeeessss',\n",
              " 'yyyeeeesssssss',\n",
              " 'yyyeeeessss',\n",
              " 'yyxplx',\n",
              " 'yyrlzr',\n",
              " 'yyou',\n",
              " 'yyeah',\n",
              " 'yye',\n",
              " 'yy',\n",
              " 'yxx',\n",
              " 'yx2',\n",
              " 'ywwh',\n",
              " 'ywsh',\n",
              " 'yws',\n",
              " 'ywhwallahwhatev',\n",
              " 'ywhs',\n",
              " 'ywhi',\n",
              " 'ywh',\n",
              " 'yweh',\n",
              " 'ywca',\n",
              " 'ywam',\n",
              " 'yw',\n",
              " 'yvshit',\n",
              " 'yvonn',\n",
              " 'yvhv',\n",
              " 'yves',\n",
              " 'yuvalwhen',\n",
              " 'yuval',\n",
              " 'yuuuuuuuuup',\n",
              " 'yuuuuuugod',\n",
              " 'yuuuuuug',\n",
              " 'yuuuuup',\n",
              " 'yuuuuug',\n",
              " 'yuuuus',\n",
              " 'yuuuup',\n",
              " 'yuuuug',\n",
              " 'yuuuu',\n",
              " 'yuuus',\n",
              " 'yuuup',\n",
              " 'yuuug',\n",
              " 'yuur',\n",
              " 'yuup',\n",
              " 'yuugest',\n",
              " 'yuug',\n",
              " 'yutub',\n",
              " 'yute',\n",
              " 'yusufiyah',\n",
              " 'yusuf',\n",
              " 'yushka',\n",
              " 'yusefor',\n",
              " 'yusef',\n",
              " 'yusdumb',\n",
              " 'yus',\n",
              " 'yuruchara',\n",
              " 'yurtl',\n",
              " 'yurt',\n",
              " 'yurop',\n",
              " 'yurok',\n",
              " 'yuri',\n",
              " 'yure',\n",
              " 'yur',\n",
              " 'yupwhat',\n",
              " 'yupwe',\n",
              " 'yupthey',\n",
              " 'yupthat',\n",
              " 'yupth',\n",
              " 'yupstep',\n",
              " 'yupsigh',\n",
              " 'yuppp',\n",
              " 'yuppleas',\n",
              " 'yuppieth',\n",
              " 'yuppi',\n",
              " 'yuppardon',\n",
              " 'yupp',\n",
              " 'yupnut',\n",
              " 'yupnow',\n",
              " 'yupnot',\n",
              " 'yupno',\n",
              " 'yupnic',\n",
              " 'yupluckili',\n",
              " 'yuplock',\n",
              " 'yupjust',\n",
              " 'yupit',\n",
              " 'yuphilari',\n",
              " 'yupgtwhen',\n",
              " 'yupgtrichard',\n",
              " 'yupgth',\n",
              " 'yupeven',\n",
              " 'yupdo',\n",
              " 'yupcant',\n",
              " 'yupbut',\n",
              " 'yupani',\n",
              " 'yupampx200bsend',\n",
              " 'yupalso',\n",
              " 'yup',\n",
              " 'yuonopoli',\n",
              " 'yuo',\n",
              " 'yunnow',\n",
              " 'yunno',\n",
              " 'yunnan',\n",
              " 'yungxannyit',\n",
              " 'yung',\n",
              " 'yunedit',\n",
              " 'yuna',\n",
              " 'yun',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT467ANbN6VW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "12717988-3aa8-4616-b753-33d8f94519e5"
      },
      "source": [
        "v = tfidf_atheism[0, :].toarray()\n",
        "\n",
        "# compute the most common value\n",
        "c = Counter(v[0])\n",
        "print(c.most_common(1))\n",
        "\n",
        "print(f\"min: {v.min()}\")\n",
        "print(f\"avg: {v.mean()}\")\n",
        "print(f\"max: {v.max()}\")\n",
        "print(f\"std: {v.std()}\")\n",
        "print(f\"mode: {c.most_common(1)}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0.0, 368448)]\n",
            "min: 0.0\n",
            "avg: 6.787677600650915e-06\n",
            "max: 0.604656600280137\n",
            "std: 0.0016474190610529808\n",
            "mode: [(0.0, 368448)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nOlCYolJ3j1",
        "colab_type": "text"
      },
      "source": [
        "### Count vectorizer - atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdQG1Xw79a_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "\n",
        "bag_of_words_atheism = nltk.word_tokenize(df_atheism['body'].to_string())\n",
        "bag_of_words_atheism = list(dict.fromkeys(bag_of_words_atheism))\n",
        "print(bag_of_words_atheism[:10])\n",
        "print(len(bag_of_words_atheism)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-O2enXnJ35U",
        "colab_type": "code",
        "outputId": "346e1eda-f19a-4dec-acfb-7b7ee71cce45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "count_vectors_atheism = CountVectorizer(ngram_range=(1,2), strip_accents=\"unicode\", encoding='utf-8')\n",
        "\n",
        "train_term_count_autheism = count_vectors.fit_transform(df_split['X_train'].astype(str))\n",
        "test_term_count_autheism = count_vectors.transform(df_split['X_val'].astype(str))\n",
        "test_term_count_autheism = count_vectors.transform(df_split['X_val'].astype(str))\n",
        "\n",
        "train_term_count_autheism"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7583345x27033690 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 200463859 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUTMnfU_9nVQ",
        "colab_type": "code",
        "outputId": "0922d22b-24ae-4394-8720-925a3b89862c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "count_vectors_atheism.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '00 00',\n",
              " '00 000',\n",
              " '00 0030',\n",
              " '00 01',\n",
              " '00 01100',\n",
              " '00 02',\n",
              " '00 04',\n",
              " '00 06',\n",
              " '00 10',\n",
              " '00 100',\n",
              " '00 11',\n",
              " '00 12',\n",
              " '00 1214',\n",
              " '00 16',\n",
              " '00 18',\n",
              " '00 190',\n",
              " '00 1900',\n",
              " '00 1i',\n",
              " '00 1just',\n",
              " '00 20',\n",
              " '00 207',\n",
              " '00 21',\n",
              " '00 22',\n",
              " '00 24',\n",
              " '00 2d',\n",
              " '00 310',\n",
              " '00 350',\n",
              " '00 3ellington',\n",
              " '00 40',\n",
              " '00 411',\n",
              " '00 610',\n",
              " '00 80',\n",
              " '00 90s',\n",
              " '00 91',\n",
              " '00 99',\n",
              " '00 absolut',\n",
              " '00 actual',\n",
              " '00 add',\n",
              " '00 agent',\n",
              " '00 aim',\n",
              " '00 alex',\n",
              " '00 alot',\n",
              " '00 american',\n",
              " '00 amv',\n",
              " '00 annoy',\n",
              " '00 anymor',\n",
              " '00 apr',\n",
              " '00 astonish',\n",
              " '00 aw',\n",
              " '00 axe',\n",
              " '00 ayrshir',\n",
              " '00 bad',\n",
              " '00 basic',\n",
              " '00 battl',\n",
              " '00 bbc',\n",
              " '00 believ',\n",
              " '00 benzodiazepin',\n",
              " '00 best',\n",
              " '00 better',\n",
              " '00 birth',\n",
              " '00 blkpg',\n",
              " '00 bob',\n",
              " '00 boost',\n",
              " '00 bpmprigioni',\n",
              " '00 breakthrough',\n",
              " '00 buck',\n",
              " '00 buckshot',\n",
              " '00 byte',\n",
              " '00 calori',\n",
              " '00 came',\n",
              " '00 camri',\n",
              " '00 cap',\n",
              " '00 caputo',\n",
              " '00 carb',\n",
              " '00 carreer',\n",
              " '00 case',\n",
              " '00 casualti',\n",
              " '00 caus',\n",
              " '00 center',\n",
              " '00 chanc',\n",
              " '00 charg',\n",
              " '00 clear',\n",
              " '00 collect',\n",
              " '00 comedi',\n",
              " '00 conclud',\n",
              " '00 congress',\n",
              " '00 consist',\n",
              " '00 coordin',\n",
              " '00 corolla',\n",
              " '00 cp3',\n",
              " '00 crazi',\n",
              " '00 crskyfal',\n",
              " '00 crucial',\n",
              " '00 cultur',\n",
              " '00 cunt',\n",
              " '00 current',\n",
              " '00 cuzz',\n",
              " '00 dad',\n",
              " '00 day',\n",
              " '00 death',\n",
              " '00 depend',\n",
              " '00 depp',\n",
              " '00 despit',\n",
              " '00 dice',\n",
              " '00 die',\n",
              " '00 draw',\n",
              " '00 drove',\n",
              " '00 dude',\n",
              " '00 dumb',\n",
              " '00 dunno',\n",
              " '00 earli',\n",
              " '00 edit',\n",
              " '00 effici',\n",
              " '00 elect',\n",
              " '00 eminem',\n",
              " '00 end',\n",
              " '00 enforc',\n",
              " '00 enorm',\n",
              " '00 ensur',\n",
              " '00 equal',\n",
              " '00 eu',\n",
              " '00 eventu',\n",
              " '00 exact',\n",
              " '00 explain',\n",
              " '00 explan',\n",
              " '00 eye',\n",
              " '00 face',\n",
              " '00 fact',\n",
              " '00 fail',\n",
              " '00 fan',\n",
              " '00 felix',\n",
              " '00 figur',\n",
              " '00 final',\n",
              " '00 find',\n",
              " '00 fine',\n",
              " '00 fli',\n",
              " '00 flip',\n",
              " '00 flour',\n",
              " '00 ft',\n",
              " '00 fusion',\n",
              " '00 gabriel',\n",
              " '00 game',\n",
              " '00 gaug',\n",
              " '00 gel',\n",
              " '00 generat',\n",
              " '00 german',\n",
              " '00 go',\n",
              " '00 goal',\n",
              " '00 good',\n",
              " '00 got',\n",
              " '00 great',\n",
              " '00 gt',\n",
              " '00 guess',\n",
              " '00 guy',\n",
              " '00 haha',\n",
              " '00 harden',\n",
              " '00 hate',\n",
              " '00 hear',\n",
              " '00 heard',\n",
              " '00 hell',\n",
              " '00 help',\n",
              " '00 high',\n",
              " '00 hope',\n",
              " '00 hour',\n",
              " '00 ice',\n",
              " '00 idea',\n",
              " '00 imo',\n",
              " '00 import',\n",
              " '00 inflat',\n",
              " '00 instead',\n",
              " '00 internet',\n",
              " '00 iron',\n",
              " '00 jordan',\n",
              " '00 kept',\n",
              " '00 kid',\n",
              " '00 kind',\n",
              " '00 kinda',\n",
              " '00 know',\n",
              " '00 knowledg',\n",
              " '00 laker',\n",
              " '00 lead',\n",
              " '00 lebron',\n",
              " '00 like',\n",
              " '00 limit',\n",
              " '00 list',\n",
              " '00 littl',\n",
              " '00 london',\n",
              " '00 longer',\n",
              " '00 look',\n",
              " '00 make',\n",
              " '00 malm',\n",
              " '00 massiv',\n",
              " '00 match',\n",
              " '00 math',\n",
              " '00 matrix',\n",
              " '00 mean',\n",
              " '00 memphi',\n",
              " '00 merced',\n",
              " '00 minor',\n",
              " '00 minut',\n",
              " '00 misogynist',\n",
              " '00 miss',\n",
              " '00 mom',\n",
              " '00 morph',\n",
              " '00 ms',\n",
              " '00 multiplay',\n",
              " '00 mvp',\n",
              " '00 nba',\n",
              " '00 negat',\n",
              " '00 nevermind',\n",
              " '00 new',\n",
              " '00 nintendo',\n",
              " '00 nippl',\n",
              " '00 nowaday',\n",
              " '00 nt',\n",
              " '00 number',\n",
              " '00 opiat',\n",
              " '00 opinion',\n",
              " '00 pant',\n",
              " '00 part',\n",
              " '00 past',\n",
              " '00 peopl',\n",
              " '00 percent',\n",
              " '00 person',\n",
              " '00 philosophi',\n",
              " '00 photo',\n",
              " '00 pivot',\n",
              " '00 place',\n",
              " '00 playoff',\n",
              " '00 pm',\n",
              " '00 point',\n",
              " '00 pop',\n",
              " '00 portland',\n",
              " '00 pretti',\n",
              " '00 prime',\n",
              " '00 probabl',\n",
              " '00 program',\n",
              " '00 progress',\n",
              " '00 promot',\n",
              " '00 protest',\n",
              " '00 proxi',\n",
              " '00 qualifi',\n",
              " '00 quick',\n",
              " '00 rabsoluteunit',\n",
              " '00 radio',\n",
              " '00 raiser',\n",
              " '00 raptor',\n",
              " '00 rare',\n",
              " '00 read',\n",
              " '00 reason',\n",
              " '00 recess',\n",
              " '00 redid',\n",
              " '00 ref',\n",
              " '00 relat',\n",
              " '00 relev',\n",
              " '00 remark',\n",
              " '00 rememb',\n",
              " '00 remov',\n",
              " '00 report',\n",
              " '00 result',\n",
              " '00 reward',\n",
              " '00 right',\n",
              " '00 road',\n",
              " '00 roma',\n",
              " '00 round',\n",
              " '00 ruin',\n",
              " '00 run',\n",
              " '00 rush',\n",
              " '00 s10',\n",
              " '00 said',\n",
              " '00 say',\n",
              " '00 season',\n",
              " '00 second',\n",
              " '00 sedit',\n",
              " '00 seen',\n",
              " '00 segway',\n",
              " '00 seri',\n",
              " '00 server',\n",
              " '00 shaq',\n",
              " '00 shaqstamina',\n",
              " '00 shitti',\n",
              " '00 shrug',\n",
              " '00 si',\n",
              " '00 sif',\n",
              " '00 skareem',\n",
              " '00 slot',\n",
              " '00 spent',\n",
              " '00 spiderman',\n",
              " '00 spur',\n",
              " '00 spurssun',\n",
              " '00 start',\n",
              " '00 stat',\n",
              " '00 status',\n",
              " '00 sthis',\n",
              " '00 straightedg',\n",
              " '00 stress',\n",
              " '00 student',\n",
              " '00 superson',\n",
              " '00 superstar',\n",
              " '00 sure',\n",
              " '00 surpris',\n",
              " '00 swear',\n",
              " '00 taken',\n",
              " '00 talent',\n",
              " '00 tatum',\n",
              " '00 team',\n",
              " '00 teemo',\n",
              " '00 teen',\n",
              " '00 ten',\n",
              " '00 thank',\n",
              " '00 thing',\n",
              " '00 think',\n",
              " '00 thought',\n",
              " '00 time',\n",
              " '00 timelin',\n",
              " '00 token',\n",
              " '00 toler',\n",
              " '00 tone',\n",
              " '00 track',\n",
              " '00 trajectori',\n",
              " '00 trash',\n",
              " '00 tri',\n",
              " '00 trl',\n",
              " '00 true',\n",
              " '00 tt',\n",
              " '00 turkey',\n",
              " '00 unbreak',\n",
              " '00 undefin',\n",
              " '00 underfund',\n",
              " '00 usdt',\n",
              " '00 vault',\n",
              " '00 video',\n",
              " '00 vorpbarn',\n",
              " '00 vs',\n",
              " '00 want',\n",
              " '00 wast',\n",
              " '00 watch',\n",
              " '00 way',\n",
              " '00 wednesday',\n",
              " '00 went',\n",
              " '00 west',\n",
              " '00 wheat',\n",
              " '00 wicker',\n",
              " '00 winner',\n",
              " '00 wonder',\n",
              " '00 work',\n",
              " '00 wors',\n",
              " '00 wow',\n",
              " '00 xmen',\n",
              " '00 yea',\n",
              " '00 year',\n",
              " '00 zero',\n",
              " '000',\n",
              " '000 00',\n",
              " '000 000',\n",
              " '000 0000',\n",
              " '000 0000001',\n",
              " '000 00025',\n",
              " '000 000can',\n",
              " '000 000r',\n",
              " '000 000s',\n",
              " '000 001',\n",
              " '000 003',\n",
              " '000 005',\n",
              " '000 007',\n",
              " '000 015',\n",
              " '000 030',\n",
              " '000 10',\n",
              " '000 100',\n",
              " '000 1000',\n",
              " '000 10k',\n",
              " '000 11',\n",
              " '000 110m2',\n",
              " '000 1141',\n",
              " '000 12',\n",
              " '000 120',\n",
              " '000 1200',\n",
              " '000 146',\n",
              " '000 15',\n",
              " '000 150',\n",
              " '000 190',\n",
              " '000 1940s',\n",
              " '000 1960',\n",
              " '000 1989',\n",
              " '000 1990',\n",
              " '000 1994',\n",
              " '000 20',\n",
              " '000 200',\n",
              " '000 2000',\n",
              " '000 2010',\n",
              " '000 20102050',\n",
              " '000 2013',\n",
              " '000 2017',\n",
              " '000 23',\n",
              " '000 2359',\n",
              " '000 2400',\n",
              " '000 25',\n",
              " '000 268',\n",
              " '000 27',\n",
              " '000 27k',\n",
              " '000 30',\n",
              " '000 300',\n",
              " '000 3000',\n",
              " '000 311usa',\n",
              " '000 319',\n",
              " '000 36turkey',\n",
              " '000 39',\n",
              " '000 3p',\n",
              " '000 40',\n",
              " '000 400',\n",
              " '000 4000',\n",
              " '000 45',\n",
              " '000 450',\n",
              " '000 50',\n",
              " '000 500',\n",
              " '000 519000',\n",
              " '000 522',\n",
              " '000 53',\n",
              " '000 585000',\n",
              " '000 600',\n",
              " '000 700',\n",
              " '000 7000',\n",
              " '000 725i',\n",
              " '000 750',\n",
              " '000 80',\n",
              " '000 911',\n",
              " '000 931000',\n",
              " '000 955000',\n",
              " '000 abort',\n",
              " '000 accept',\n",
              " '000 accord',\n",
              " '000 account',\n",
              " '000 acr',\n",
              " '000 activ',\n",
              " '000 actual',\n",
              " '000 ad',\n",
              " '000 addict',\n",
              " '000 addit',\n",
              " '000 african',\n",
              " '000 agreement',\n",
              " '000 ah',\n",
              " '000 aircraft',\n",
              " '000 albanian',\n",
              " '000 albin',\n",
              " '000 alcohol',\n",
              " '000 alien',\n",
              " '000 alli',\n",
              " '000 allow',\n",
              " '000 amaz',\n",
              " '000 amend',\n",
              " '000 american',\n",
              " '000 ancestor',\n",
              " '000 annual',\n",
              " '000 annum',\n",
              " '000 answer',\n",
              " '000 antart',\n",
              " '000 anzac',\n",
              " '000 area',\n",
              " '000 armenian',\n",
              " '000 articl',\n",
              " '000 ask',\n",
              " '000 assum',\n",
              " '000 asylum',\n",
              " '000 aud',\n",
              " '000 australia',\n",
              " '000 bad',\n",
              " '000 bank',\n",
              " '000 basic',\n",
              " '000 battl',\n",
              " '000 bc',\n",
              " '000 bce',\n",
              " '000 becquerel',\n",
              " '000 belgian',\n",
              " '000 best',\n",
              " '000 bicycl',\n",
              " '000 big',\n",
              " '000 biljon',\n",
              " '000 billion',\n",
              " '000 birdshot',\n",
              " '000 birth',\n",
              " '000 birthright',\n",
              " '000 birthsgood',\n",
              " '000 bit',\n",
              " '000 block',\n",
              " '000 bonsai',\n",
              " '000 book',\n",
              " '000 bosnians51',\n",
              " '000 bought',\n",
              " '000 brazil',\n",
              " '000 bremen',\n",
              " '000 bribe',\n",
              " '000 british',\n",
              " '000 briton',\n",
              " '000 btc',\n",
              " '000 buck',\n",
              " '000 bucket',\n",
              " '000 bulgarian',\n",
              " '000 buy',\n",
              " '000 bystand',\n",
              " '000 cabl',\n",
              " '000 cal',\n",
              " '000 calori',\n",
              " '000 calssecond',\n",
              " '000 camp',\n",
              " '000 canadian',\n",
              " '000 cancer',\n",
              " '000 capit',\n",
              " '000 capita',\n",
              " '000 car',\n",
              " '000 care',\n",
              " '000 carri',\n",
              " '000 case',\n",
              " '000 cash',\n",
              " '000 casualti',\n",
              " '000 categori',\n",
              " '000 cavalri',\n",
              " '000 challeng',\n",
              " '000 chanc',\n",
              " '000 channel',\n",
              " '000 chechen',\n",
              " '000 check',\n",
              " '000 childhood',\n",
              " '000 children',\n",
              " '000 chilean',\n",
              " '000 chines',\n",
              " '000 christian',\n",
              " '000 citi',\n",
              " '000 citiz',\n",
              " '000 citizen',\n",
              " '000 citizensi',\n",
              " '000 civilian',\n",
              " '000 closet',\n",
              " '000 coder',\n",
              " '000 come',\n",
              " '000 comment',\n",
              " '000 common',\n",
              " '000 communist',\n",
              " '000 compani',\n",
              " '000 comput',\n",
              " '000 confid',\n",
              " '000 confirm',\n",
              " '000 conquistador',\n",
              " '000 conscript',\n",
              " '000 contain',\n",
              " '000 contrast',\n",
              " '000 convert',\n",
              " '000 corps',\n",
              " '000 count',\n",
              " '000 countgtit',\n",
              " '000 countri',\n",
              " '000 crime',\n",
              " '000 crisi',\n",
              " '000 croatian',\n",
              " '000 crowd',\n",
              " '000 czech',\n",
              " '000 danger',\n",
              " '000 data',\n",
              " '000 day',\n",
              " '000 daysi',\n",
              " '000 de',\n",
              " '000 dead',\n",
              " '000 deal',\n",
              " '000 death',\n",
              " '000 debt',\n",
              " '000 decid',\n",
              " '000 decor',\n",
              " '000 definit',\n",
              " '000 degre',\n",
              " '000 delay',\n",
              " '000 delet',\n",
              " '000 demandsno',\n",
              " '000 demonstrat',\n",
              " '000 depemdan',\n",
              " '000 depend',\n",
              " '000 deporte',\n",
              " '000 devastatedtireddaz',\n",
              " '000 develop',\n",
              " '000 diarrhoea',\n",
              " '000 didbut',\n",
              " '000 die',\n",
              " '000 differ',\n",
              " '000 dinar',\n",
              " '000 direct',\n",
              " '000 displac',\n",
              " '000 dive',\n",
              " '000 doable131',\n",
              " '000 dollar',\n",
              " '000 dtp',\n",
              " '000 dude2',\n",
              " '000 dutch',\n",
              " '000 earli',\n",
              " '000 effect',\n",
              " '000 elig',\n",
              " '000 embrac',\n",
              " '000 emerg',\n",
              " '000 emigr',\n",
              " '000 employe',\n",
              " '000 end',\n",
              " '000 endang',\n",
              " '000 engag',\n",
              " '000 engin',\n",
              " '000 entir',\n",
              " '000 estim',\n",
              " '000 ethnic',\n",
              " '000 eu',\n",
              " '000 eur',\n",
              " '000 eurher',\n",
              " '000 euro',\n",
              " '000 european',\n",
              " '000 everybodi',\n",
              " '000 exampl',\n",
              " '000 excess',\n",
              " '000 exchang',\n",
              " '000 exclus',\n",
              " '000 export',\n",
              " '000 extra',\n",
              " '000 extrem',\n",
              " '000 fan',\n",
              " '000 fanat',\n",
              " '000 far',\n",
              " '000 farm',\n",
              " '000 farmer',\n",
              " '000 fellow',\n",
              " '000 fiftysix',\n",
              " '000 figur',\n",
              " '000 fine',\n",
              " '000 fineor',\n",
              " '000 finland',\n",
              " '000 finlndar',\n",
              " '000 finn',\n",
              " '000 finns141',\n",
              " '000 fire',\n",
              " '000 firearm',\n",
              " '000 fit',\n",
              " '000 flighthour',\n",
              " '000 florida',\n",
              " '000 food',\n",
              " '000 footnot',\n",
              " '000 foreign',\n",
              " '000 foreignalien',\n",
              " '000 forev',\n",
              " '000 fortenit',\n",
              " '000 forther',\n",
              " '000 found',\n",
              " '000 fps',\n",
              " '000 french',\n",
              " '000 friday',\n",
              " '000 ft',\n",
              " '000 fuck',\n",
              " '000 fuckin',\n",
              " '000 fuel',\n",
              " '000 gain',\n",
              " '000 gallon',\n",
              " '000 gdp',\n",
              " '000 generat',\n",
              " '000 german',\n",
              " '000 germani',\n",
              " '000 germans48',\n",
              " '000 germanstoday',\n",
              " '000 given',\n",
              " '000 gone',\n",
              " '000 gop',\n",
              " '000 gpm',\n",
              " '000 grant',\n",
              " '000 gross',\n",
              " '000 group',\n",
              " '000 gulag',\n",
              " '000 gun',\n",
              " '000 guy',\n",
              " '000 gwh',\n",
              " '000 ha',\n",
              " '000 half',\n",
              " '000 hand',\n",
              " '000 harki',\n",
              " '000 hate',\n",
              " '000 heart',\n",
              " '000 heat',\n",
              " '000 hectar',\n",
              " '000 hektar',\n",
              " '000 hell',\n",
              " '000 hello',\n",
              " '000 help',\n",
              " '000 high',\n",
              " '000 hippo',\n",
              " '000 hold',\n",
              " '000 holi',\n",
              " '000 holiday',\n",
              " '000 homeless',\n",
              " '000 hour',\n",
              " '000 huge',\n",
              " '000 hungari',\n",
              " '000 hungarian',\n",
              " '000 ignor',\n",
              " '000 ili',\n",
              " '000 immedi',\n",
              " '000 immigr',\n",
              " '000 imperium',\n",
              " '000 inappropri',\n",
              " '000 incid',\n",
              " '000 includ',\n",
              " '000 increas',\n",
              " '000 incred',\n",
              " '000 indic',\n",
              " '000 individu',\n",
              " '000 inflationthat',\n",
              " '000 inhabit',\n",
              " '000 insid',\n",
              " '000 internet',\n",
              " '000 invest',\n",
              " '000 iranians66',\n",
              " '000 iraqis91',\n",
              " '000 isra',\n",
              " '000 itali',\n",
              " '000 italian',\n",
              " '000 janaug',\n",
              " '000 jeti',\n",
              " '000 jew',\n",
              " '000 jewish',\n",
              " '000 job',\n",
              " '000 jon',\n",
              " '000 judt',\n",
              " '000 karma',\n",
              " '000 kcal',\n",
              " '000 kcalday',\n",
              " '000 kg',\n",
              " '000 kgi',\n",
              " '000 kill',\n",
              " '000 kilo',\n",
              " '000 kilogram',\n",
              " '000 kinda',\n",
              " '000 km',\n",
              " '000 km2',\n",
              " '000 kms',\n",
              " '000 kmthey',\n",
              " '000 know',\n",
              " '000 kosovan',\n",
              " '000 kronor',\n",
              " '000 kuna',\n",
              " '000 kurd',\n",
              " '000 lake',\n",
              " '000 languag',\n",
              " '000 later',\n",
              " '000 latest',\n",
              " '000 latvian',\n",
              " '000 lawyer',\n",
              " '000 left',\n",
              " '000 legal',\n",
              " '000 lei',\n",
              " '000 lel',\n",
              " '000 life',\n",
              " '000 light',\n",
              " '000 like',\n",
              " '000 likelihood',\n",
              " '000 line',\n",
              " '000 link',\n",
              " '000 listen',\n",
              " '000 liter',\n",
              " '000 lithuanian',\n",
              " '000 live',\n",
              " '000 log102',\n",
              " '000 london',\n",
              " '000 long',\n",
              " '000 loot',\n",
              " '000 loss',\n",
              " '000 lost',\n",
              " '000 lot',\n",
              " '000 love',\n",
              " '000 low',\n",
              " '000 lower',\n",
              " '000 lt',\n",
              " '000 lux',\n",
              " '000 luxdirect',\n",
              " '000 luxemburg',\n",
              " '000 ly',\n",
              " '000 m2',\n",
              " '000 m22',\n",
              " '000 macedonian',\n",
              " '000 mah',\n",
              " '000 main',\n",
              " '000 make',\n",
              " '000 malaria',\n",
              " '000 male',\n",
              " '000 man',\n",
              " '000 manag',\n",
              " '000 map',\n",
              " '000 math',\n",
              " '000 mauritius',\n",
              " '000 mayb',\n",
              " '000 mb',\n",
              " '000 mbts',\n",
              " '000 member',\n",
              " '000 men',\n",
              " '000 microsoft',\n",
              " '000 middl',\n",
              " '000 midnight',\n",
              " '000 mile',\n",
              " '000 militia',\n",
              " '000 miljard',\n",
              " '000 miljon',\n",
              " '000 miljoonait',\n",
              " '000 million',\n",
              " '000 miniscul',\n",
              " '000 minor',\n",
              " '000 minut',\n",
              " '000 mistak',\n",
              " '000 mmoll',\n",
              " '000 monkey',\n",
              " '000 month',\n",
              " '000 moos',\n",
              " '000 morehonest',\n",
              " '000 moroccan',\n",
              " '000 morrocan',\n",
              " '000 move',\n",
              " '000 movi',\n",
              " '000 muslim',\n",
              " '000 na',\n",
              " '000 nativ',\n",
              " '000 near',\n",
              " '000 need',\n",
              " '000 net',\n",
              " '000 neuron',\n",
              " '000 new',\n",
              " '000 nis',\n",
              " '000 nok',\n",
              " '000 nomin',\n",
              " '000 noncitizens2011',\n",
              " '000 noneuropean',\n",
              " '000 nonwhit',\n",
              " '000 normal',\n",
              " '000 north',\n",
              " '000 northeastern',\n",
              " '000 note',\n",
              " '000 nothingi',\n",
              " '000 notori',\n",
              " '000 nowaday',\n",
              " '000 nt',\n",
              " '000 number',\n",
              " '000 offici',\n",
              " '000 oh',\n",
              " '000 old',\n",
              " '000 oper',\n",
              " '000 origin',\n",
              " '000 page',\n",
              " '000 palestinian',\n",
              " '000 parchment',\n",
              " '000 particip',\n",
              " '000 pascal',\n",
              " '000 pay',\n",
              " '000 pc',\n",
              " '000 peasant',\n",
              " '000 pend',\n",
              " '000 pengo',\n",
              " '000 peopl',\n",
              " '000 peoplealso',\n",
              " '000 peopleand',\n",
              " '000 peoplebuahahaha45000',\n",
              " '000 peoplehad',\n",
              " '000 peopleontario',\n",
              " '000 peopleso',\n",
              " '000 peoplewhich',\n",
              " '000 perman',\n",
              " '000 person',\n",
              " '000 personnel',\n",
              " '000 personyear',\n",
              " '000 peryeargt',\n",
              " '000 peso',\n",
              " '000 piec',\n",
              " '000 play',\n",
              " '000 pln',\n",
              " '000 plus',\n",
              " '000 plz',\n",
              " '000 podesta',\n",
              " '000 point',\n",
              " '000 pole',\n",
              " '000 poles74',\n",
              " '000 polic',\n",
              " '000 policemen',\n",
              " '000 polish',\n",
              " '000 pontic',\n",
              " '000 pop',\n",
              " '000 popul',\n",
              " '000 populationmi',\n",
              " '000 posit',\n",
              " '000 pound',\n",
              " '000 power',\n",
              " '000 ppl',\n",
              " '000 preorder',\n",
              " '000 present',\n",
              " '000 pretti',\n",
              " '000 priest',\n",
              " '000 prize',\n",
              " '000 profit',\n",
              " '000 proteincod',\n",
              " '000 rais',\n",
              " '000 rakver',\n",
              " '000 random',\n",
              " '000 rang',\n",
              " '000 rarest',\n",
              " '000 rate',\n",
              " '000 reaction',\n",
              " '000 real',\n",
              " '000 realiti',\n",
              " '000 rebel',\n",
              " '000 receiv',\n",
              " '000 recent',\n",
              " '000 recogn',\n",
              " '000 refug',\n",
              " '000 refuge',\n",
              " '000 regist',\n",
              " '000 regular',\n",
              " '000 reject',\n",
              " '000 relat',\n",
              " '000 remark',\n",
              " '000 renault',\n",
              " '000 repetit',\n",
              " '000 report',\n",
              " '000 request',\n",
              " '000 reserv',\n",
              " '000 resettl',\n",
              " '000 resid',\n",
              " '000 respons',\n",
              " '000 retir',\n",
              " '000 return',\n",
              " '000 right',\n",
              " '000 risk',\n",
              " '000 roubl',\n",
              " '000 rough',\n",
              " '000 roughlyfr',\n",
              " '000 round',\n",
              " '000 rubl',\n",
              " '000 run',\n",
              " '000 russian',\n",
              " '000 russianspeak',\n",
              " '000 said',\n",
              " '000 sampl',\n",
              " '000 scientif',\n",
              " '000 scream',\n",
              " '000 screen',\n",
              " '000 second',\n",
              " '000 select',\n",
              " '000 sell',\n",
              " '000 serb',\n",
              " '000 serial',\n",
              " '000 serious',\n",
              " '000 session',\n",
              " '000 sever',\n",
              " '000 shade',\n",
              " '000 share',\n",
              " '000 shit',\n",
              " '000 short',\n",
              " '000 sign',\n",
              " '000 signatur',\n",
              " '000 similar',\n",
              " '000 singl',\n",
              " '000 sita',\n",
              " '000 site',\n",
              " '000 slav',\n",
              " '000 smaller',\n",
              " '000 soldier',\n",
              " '000 somali',\n",
              " '000 somewhat',\n",
              " '000 son',\n",
              " '000 sorri',\n",
              " '000 sound',\n",
              " '000 sourc',\n",
              " '000 south',\n",
              " '000 soviet',\n",
              " '000 soyboy',\n",
              " '000 spain',\n",
              " '000 speaker',\n",
              " '000 speci',\n",
              " '000 spent',\n",
              " '000 spider',\n",
              " '000 sq',\n",
              " '000 squar',\n",
              " '000 srba',\n",
              " '000 start',\n",
              " '000 state',\n",
              " '000 stay',\n",
              " '000 steal',\n",
              " '000 steam',\n",
              " '000 step',\n",
              " '000 storag',\n",
              " '000 stori',\n",
              " '000 storm',\n",
              " '000 strong',\n",
              " '000 student',\n",
              " '000 studi',\n",
              " '000 subject',\n",
              " '000 subscrib',\n",
              " '000 success',\n",
              " '000 surviv',\n",
              " '000 suspect',\n",
              " '000 swede',\n",
              " '000 swim',\n",
              " '000 syria',\n",
              " '000 syrians151',\n",
              " '000 t34s',\n",
              " '000 tabqa',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYwKDfwZKhMm",
        "colab_type": "code",
        "outputId": "c29e6758-dddb-4ab2-c228-026c1a8f4e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "v = train_term_count_atheism[0, :].toarray()\n",
        "\n",
        "# compute the most common value\n",
        "c = Counter(v[0])\n",
        "print(c.most_common(1))\n",
        "\n",
        "print(f\"min: {v.min()}\")\n",
        "print(f\"avg: {v.mean()}\")\n",
        "print(f\"max: {v.max()}\")\n",
        "print(f\"std: {v.std()}\")\n",
        "print(f\"mode: {c.most_common(1)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 27033689)]\n",
            "min: 0\n",
            "avg: 3.6990880638196264e-08\n",
            "max: 1\n",
            "std: 0.00019233013094643186\n",
            "mode: [(0, 27033689)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXGwIi5f8c0V",
        "colab_type": "code",
        "outputId": "88c460a4-a691-48ef-c656-136e1fb266a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "list(count_vectors.vocabulary_.keys())[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['think',\n",
              " 'submiss',\n",
              " 'removedviol',\n",
              " 'rule',\n",
              " 'thread',\n",
              " 'answer',\n",
              " 'wiki',\n",
              " 'search',\n",
              " 'rfit',\n",
              " 'googl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTEVVhzgWzu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectors_atheism.wv.most_similar(\"pope\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZcfUPYeDWcP",
        "colab_type": "text"
      },
      "source": [
        "### FastText vectorization - atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-QTzm5-FwP-",
        "colab_type": "code",
        "outputId": "d9e4fc43-08cf-4be4-98df-1e4d36ff345a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let us start by downloading the most recent release\n",
        "\n",
        "!wget https://github.com/facebookresearch/fastText/archive/v0.9.1.zip\n",
        "!unzip v0.9.1.zip"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-23 22:05:34--  https://github.com/facebookresearch/fastText/archive/v0.9.1.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/facebookresearch/fastText/zip/v0.9.1 [following]\n",
            "--2019-11-23 22:05:34--  https://codeload.github.com/facebookresearch/fastText/zip/v0.9.1\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘v0.9.1.zip’\n",
            "\n",
            "v0.9.1.zip              [  <=>               ]   4.13M  10.4MB/s    in 0.4s    \n",
            "\n",
            "2019-11-23 22:05:35 (10.4 MB/s) - ‘v0.9.1.zip’ saved [4327207]\n",
            "\n",
            "Archive:  v0.9.1.zip\n",
            "b5b7d307274ce00ef52198fbc692ed3bd11d9856\n",
            "   creating: fastText-0.9.1/\n",
            "   creating: fastText-0.9.1/.circleci/\n",
            "  inflating: fastText-0.9.1/.circleci/cmake_test.sh  \n",
            "  inflating: fastText-0.9.1/.circleci/config.yml  \n",
            "  inflating: fastText-0.9.1/.circleci/gcc_test.sh  \n",
            "  inflating: fastText-0.9.1/.circleci/pip_test.sh  \n",
            "  inflating: fastText-0.9.1/.circleci/pull_data.sh  \n",
            "  inflating: fastText-0.9.1/.circleci/python_test.sh  \n",
            "  inflating: fastText-0.9.1/.circleci/run_locally.sh  \n",
            "  inflating: fastText-0.9.1/.circleci/setup_circleimg.sh  \n",
            "  inflating: fastText-0.9.1/.circleci/setup_debian.sh  \n",
            "  inflating: fastText-0.9.1/.gitignore  \n",
            "  inflating: fastText-0.9.1/CMakeLists.txt  \n",
            "  inflating: fastText-0.9.1/CODE_OF_CONDUCT.md  \n",
            "  inflating: fastText-0.9.1/CONTRIBUTING.md  \n",
            "  inflating: fastText-0.9.1/LICENSE  \n",
            "  inflating: fastText-0.9.1/MANIFEST.in  \n",
            "  inflating: fastText-0.9.1/Makefile  \n",
            "  inflating: fastText-0.9.1/README.md  \n",
            "   creating: fastText-0.9.1/alignment/\n",
            "  inflating: fastText-0.9.1/alignment/README.md  \n",
            "  inflating: fastText-0.9.1/alignment/align.py  \n",
            "  inflating: fastText-0.9.1/alignment/eval.py  \n",
            "  inflating: fastText-0.9.1/alignment/example.sh  \n",
            "  inflating: fastText-0.9.1/alignment/unsup_align.py  \n",
            "  inflating: fastText-0.9.1/alignment/utils.py  \n",
            "  inflating: fastText-0.9.1/classification-example.sh  \n",
            "  inflating: fastText-0.9.1/classification-results.sh  \n",
            "   creating: fastText-0.9.1/crawl/\n",
            "  inflating: fastText-0.9.1/crawl/README.md  \n",
            "  inflating: fastText-0.9.1/crawl/dedup.cc  \n",
            "  inflating: fastText-0.9.1/crawl/download_crawl.sh  \n",
            "  inflating: fastText-0.9.1/crawl/filter_dedup.sh  \n",
            "  inflating: fastText-0.9.1/crawl/filter_utf8.cc  \n",
            "  inflating: fastText-0.9.1/crawl/process_wet_file.sh  \n",
            "   creating: fastText-0.9.1/docs/\n",
            "  inflating: fastText-0.9.1/docs/aligned-vectors.md  \n",
            "  inflating: fastText-0.9.1/docs/api.md  \n",
            "  inflating: fastText-0.9.1/docs/cheatsheet.md  \n",
            "  inflating: fastText-0.9.1/docs/crawl-vectors.md  \n",
            "  inflating: fastText-0.9.1/docs/dataset.md  \n",
            "  inflating: fastText-0.9.1/docs/english-vectors.md  \n",
            "  inflating: fastText-0.9.1/docs/faqs.md  \n",
            "  inflating: fastText-0.9.1/docs/language-identification.md  \n",
            "  inflating: fastText-0.9.1/docs/options.md  \n",
            "  inflating: fastText-0.9.1/docs/pretrained-vectors.md  \n",
            "  inflating: fastText-0.9.1/docs/python-module.md  \n",
            "  inflating: fastText-0.9.1/docs/references.md  \n",
            "  inflating: fastText-0.9.1/docs/supervised-models.md  \n",
            "  inflating: fastText-0.9.1/docs/supervised-tutorial.md  \n",
            "  inflating: fastText-0.9.1/docs/support.md  \n",
            "  inflating: fastText-0.9.1/docs/unsupervised-tutorials.md  \n",
            "  inflating: fastText-0.9.1/eval.py  \n",
            "  inflating: fastText-0.9.1/get-wikimedia.sh  \n",
            "   creating: fastText-0.9.1/python/\n",
            "  inflating: fastText-0.9.1/python/README.md  \n",
            "  inflating: fastText-0.9.1/python/README.rst  \n",
            "   creating: fastText-0.9.1/python/benchmarks/\n",
            "  inflating: fastText-0.9.1/python/benchmarks/README.rst  \n",
            "  inflating: fastText-0.9.1/python/benchmarks/get_word_vector.py  \n",
            "   creating: fastText-0.9.1/python/doc/\n",
            "   creating: fastText-0.9.1/python/doc/examples/\n",
            "  inflating: fastText-0.9.1/python/doc/examples/FastTextEmbeddingBag.py  \n",
            "  inflating: fastText-0.9.1/python/doc/examples/bin_to_vec.py  \n",
            "  inflating: fastText-0.9.1/python/doc/examples/compute_accuracy.py  \n",
            "  inflating: fastText-0.9.1/python/doc/examples/get_vocab.py  \n",
            "  inflating: fastText-0.9.1/python/doc/examples/train_supervised.py  \n",
            "  inflating: fastText-0.9.1/python/doc/examples/train_unsupervised.py  \n",
            "   creating: fastText-0.9.1/python/fasttext_module/\n",
            "   creating: fastText-0.9.1/python/fasttext_module/fasttext/\n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/FastText.py  \n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/__init__.py  \n",
            "   creating: fastText-0.9.1/python/fasttext_module/fasttext/pybind/\n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/pybind/fasttext_pybind.cc  \n",
            "   creating: fastText-0.9.1/python/fasttext_module/fasttext/tests/\n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/tests/__init__.py  \n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/tests/test_configurations.py  \n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/tests/test_script.py  \n",
            "   creating: fastText-0.9.1/python/fasttext_module/fasttext/util/\n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/util/__init__.py  \n",
            "  inflating: fastText-0.9.1/python/fasttext_module/fasttext/util/util.py  \n",
            "  inflating: fastText-0.9.1/quantization-example.sh  \n",
            "  inflating: fastText-0.9.1/runtests.py  \n",
            "   creating: fastText-0.9.1/scripts/\n",
            "   creating: fastText-0.9.1/scripts/kbcompletion/\n",
            "  inflating: fastText-0.9.1/scripts/kbcompletion/README.md  \n",
            "  inflating: fastText-0.9.1/scripts/kbcompletion/data.sh  \n",
            "  inflating: fastText-0.9.1/scripts/kbcompletion/eval.cpp  \n",
            "  inflating: fastText-0.9.1/scripts/kbcompletion/fb15k.sh  \n",
            "  inflating: fastText-0.9.1/scripts/kbcompletion/fb15k237.sh  \n",
            "  inflating: fastText-0.9.1/scripts/kbcompletion/svo.sh  \n",
            "  inflating: fastText-0.9.1/scripts/kbcompletion/wn18.sh  \n",
            "   creating: fastText-0.9.1/scripts/quantization/\n",
            "  inflating: fastText-0.9.1/scripts/quantization/quantization-results.sh  \n",
            " extracting: fastText-0.9.1/setup.cfg  \n",
            "  inflating: fastText-0.9.1/setup.py  \n",
            "   creating: fastText-0.9.1/src/\n",
            "  inflating: fastText-0.9.1/src/args.cc  \n",
            "  inflating: fastText-0.9.1/src/args.h  \n",
            "  inflating: fastText-0.9.1/src/densematrix.cc  \n",
            "  inflating: fastText-0.9.1/src/densematrix.h  \n",
            "  inflating: fastText-0.9.1/src/dictionary.cc  \n",
            "  inflating: fastText-0.9.1/src/dictionary.h  \n",
            "  inflating: fastText-0.9.1/src/fasttext.cc  \n",
            "  inflating: fastText-0.9.1/src/fasttext.h  \n",
            "  inflating: fastText-0.9.1/src/loss.cc  \n",
            "  inflating: fastText-0.9.1/src/loss.h  \n",
            "  inflating: fastText-0.9.1/src/main.cc  \n",
            "  inflating: fastText-0.9.1/src/matrix.cc  \n",
            "  inflating: fastText-0.9.1/src/matrix.h  \n",
            "  inflating: fastText-0.9.1/src/meter.cc  \n",
            "  inflating: fastText-0.9.1/src/meter.h  \n",
            "  inflating: fastText-0.9.1/src/model.cc  \n",
            "  inflating: fastText-0.9.1/src/model.h  \n",
            "  inflating: fastText-0.9.1/src/productquantizer.cc  \n",
            "  inflating: fastText-0.9.1/src/productquantizer.h  \n",
            "  inflating: fastText-0.9.1/src/quantmatrix.cc  \n",
            "  inflating: fastText-0.9.1/src/quantmatrix.h  \n",
            "  inflating: fastText-0.9.1/src/real.h  \n",
            "  inflating: fastText-0.9.1/src/utils.cc  \n",
            "  inflating: fastText-0.9.1/src/utils.h  \n",
            "  inflating: fastText-0.9.1/src/vector.cc  \n",
            "  inflating: fastText-0.9.1/src/vector.h  \n",
            "   creating: fastText-0.9.1/tests/\n",
            "  inflating: fastText-0.9.1/tests/fetch_test_data.sh  \n",
            "   creating: fastText-0.9.1/website/\n",
            "  inflating: fastText-0.9.1/website/README.md  \n",
            "   creating: fastText-0.9.1/website/blog/\n",
            "  inflating: fastText-0.9.1/website/blog/2016-08-18-blog-post.md  \n",
            "  inflating: fastText-0.9.1/website/blog/2017-05-02-blog-post.md  \n",
            "  inflating: fastText-0.9.1/website/blog/2017-10-02-blog-post.md  \n",
            "  inflating: fastText-0.9.1/website/blog/2019-06-25-blog-post.md  \n",
            "   creating: fastText-0.9.1/website/core/\n",
            "  inflating: fastText-0.9.1/website/core/Footer.js  \n",
            "  inflating: fastText-0.9.1/website/package.json  \n",
            "   creating: fastText-0.9.1/website/pages/\n",
            "   creating: fastText-0.9.1/website/pages/en/\n",
            "  inflating: fastText-0.9.1/website/pages/en/index.js  \n",
            "  inflating: fastText-0.9.1/website/sidebars.json  \n",
            "  inflating: fastText-0.9.1/website/siteConfig.js  \n",
            "   creating: fastText-0.9.1/website/static/\n",
            "   creating: fastText-0.9.1/website/static/docs/\n",
            "   creating: fastText-0.9.1/website/static/docs/en/\n",
            "   creating: fastText-0.9.1/website/static/docs/en/html/\n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/.classfasttext_1_1QMatrix-members.html.i4eKqy  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/annotated.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/annotated_dup.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/args_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/args_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/args_8h.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/args_8h_source.html  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/bc_s.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/bdwn.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classes.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Args-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Args.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Args.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Dictionary-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Dictionary.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Dictionary.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1FastText-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1FastText.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1FastText.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Matrix-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Matrix.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Matrix.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Model-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Model.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Model.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1ProductQuantizer-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1ProductQuantizer.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1QMatrix-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1QMatrix.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1QMatrix.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Vector-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Vector.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/classfasttext_1_1Vector.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/closed.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/dictionary_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/dictionary_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/dictionary_8h.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/dictionary_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/dir_68267d1309a1af8e8297ef4c3efbcdba.js  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/doc.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/doxygen.css  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/doxygen.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/dynsections.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/fasttext_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/fasttext_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/fasttext_8h.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/fasttext_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/favicon.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/files.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/files.js  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/folderclosed.png  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/folderopen.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_0x7e.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_b.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_c.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_d.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_dup.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_e.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_f.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_func.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_g.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_i.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_k.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_l.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_m.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_n.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_o.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_p.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_q.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_r.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_s.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_t.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_u.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_v.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_vars.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_w.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/functions_z.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/globals.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/globals_defs.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/globals_func.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/index.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/jquery.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/main_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/main_8cc.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/matrix_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/matrix_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/matrix_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/menu.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/menudata.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/model_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/model_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/model_8h.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/model_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespacefasttext.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespacefasttext.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespacefasttext_1_1utils.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespacemembers.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespacemembers_enum.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespacemembers_func.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespacemembers_type.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespaces.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/namespaces.js  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/nav_f.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/nav_g.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/nav_h.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/navtree.css  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/navtree.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/navtreedata.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/navtreeindex0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/navtreeindex1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/open.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/productquantizer_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/productquantizer_8cc.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/productquantizer_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/productquantizer_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/qmatrix_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/qmatrix_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/qmatrix_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/real_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/real_8h.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/real_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/resize.js  \n",
            "   creating: fastText-0.9.1/website/static/docs/en/html/search/\n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/search/.files_7.html.StRRNc  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/search/.variables_a.html.1MGQ27  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_10.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_10.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_11.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_11.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_12.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_12.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_13.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_13.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_14.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_14.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_15.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_15.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_16.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_16.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_17.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_17.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_3.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_3.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_4.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_4.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_5.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_5.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_6.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_6.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_7.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_7.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_8.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_8.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_9.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_9.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_a.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_a.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_b.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_b.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_c.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_c.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_d.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_d.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_e.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_e.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_f.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/all_f.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_3.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_3.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_4.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_4.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_5.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_5.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_6.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_6.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_7.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_7.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_8.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/classes_8.js  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/search/close.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_3.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/defines_3.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enums_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enums_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enums_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enums_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enums_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enums_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_3.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_3.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_4.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_4.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_5.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/enumvalues_5.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_3.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_3.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_4.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_4.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_5.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_5.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_6.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_6.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_7.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_7.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_8.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/files_8.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_10.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_10.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_11.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_11.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_12.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_12.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_13.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_13.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_14.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_14.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_15.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_15.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_16.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_16.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_17.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_17.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_3.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_3.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_4.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_4.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_5.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_5.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_6.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_6.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_7.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_7.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_8.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_8.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_9.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_9.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_a.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_a.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_b.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_b.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_c.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_c.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_d.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_d.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_e.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_e.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_f.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/functions_f.js  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/search/mag_sel.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/namespaces_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/namespaces_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/nomatches.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/search.css  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/search.js  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/search/search_l.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/search_m.png  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/search/search_r.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/searchdata.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/typedefs_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/typedefs_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/typedefs_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/typedefs_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_0.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_0.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_1.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_1.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_10.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_10.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_11.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_11.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_12.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_12.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_13.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_13.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_2.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_2.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_3.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_3.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_4.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_4.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_5.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_5.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_6.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_6.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_7.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_7.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_8.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_8.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_9.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_9.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_a.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_a.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_b.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_b.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_c.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_c.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_d.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_d.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_e.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_e.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_f.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/search/variables_f.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/splitbar.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/structfasttext_1_1Node-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/structfasttext_1_1Node.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/structfasttext_1_1Node.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/structfasttext_1_1entry-members.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/structfasttext_1_1entry.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/structfasttext_1_1entry.js  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/sync_off.png  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/sync_on.png  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/tab_a.png  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/tab_b.png  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/tab_h.png  \n",
            " extracting: fastText-0.9.1/website/static/docs/en/html/tab_s.png  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/tabs.css  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/utils_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/utils_8cc.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/utils_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/utils_8h.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/utils_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/vector_8cc.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/vector_8cc.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/vector_8h.html  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/vector_8h.js  \n",
            "  inflating: fastText-0.9.1/website/static/docs/en/html/vector_8h_source.html  \n",
            "  inflating: fastText-0.9.1/website/static/fasttext.css  \n",
            "   creating: fastText-0.9.1/website/static/img/\n",
            "   creating: fastText-0.9.1/website/static/img/authors/\n",
            "  inflating: fastText-0.9.1/website/static/img/authors/armand_joulin.jpg  \n",
            "  inflating: fastText-0.9.1/website/static/img/authors/christian_puhrsch.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/authors/edouard_grave.jpeg  \n",
            "  inflating: fastText-0.9.1/website/static/img/authors/piotr_bojanowski.jpg  \n",
            "  inflating: fastText-0.9.1/website/static/img/authors/tomas_mikolov.jpg  \n",
            "   creating: fastText-0.9.1/website/static/img/blog/\n",
            "  inflating: fastText-0.9.1/website/static/img/blog/2016-08-18-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/blog/2016-08-18-blog-post-img2.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/blog/2017-05-02-blog-post-img1.jpg  \n",
            "  inflating: fastText-0.9.1/website/static/img/blog/2017-05-02-blog-post-img2.jpg  \n",
            "  inflating: fastText-0.9.1/website/static/img/blog/2017-10-02-blog-post-img1.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/cbo_vs_skipgram.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-icon-api.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-icon-bg-web.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-icon-color-square.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-icon-color-web.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-icon-faq.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-icon-tutorial.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-icon-white-web.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-logo-color-web.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/fasttext-logo-white-web.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/logo-color.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/model-black.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/model-blue.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/model-red.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/ogimage.png  \n",
            "  inflating: fastText-0.9.1/website/static/img/oss_logo.png  \n",
            "  inflating: fastText-0.9.1/wikifil.pl  \n",
            "  inflating: fastText-0.9.1/word-vector-example.sh  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T2IxTC3FwJj",
        "colab_type": "code",
        "outputId": "c2c17870-d04e-444a-ba7b-2c728932308f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "%cd fastText-0.9.1\n",
        "# for command line tool :\n",
        "!make\n",
        "# for python bindings :\n",
        "!pip install ."
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fastText-0.9.1\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::quantize(const fasttext::Args&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:323:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kstd::vector<int> fasttext::FastText::selectEmbeddings(int32_t) const\u001b[m\u001b[K’ is deprecated: selectEmbeddings is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     auto idx = selectEmbeddings(qargs.cutoff\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:293:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " std::vector<int32_t> \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::selectEmbeddings(int32_t cutoff) const {\n",
            "                      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kvoid fasttext::FastText::lazyComputeWordVectors()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:551:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid fasttext::FastText::precomputeWordVectors(fasttext::DenseMatrix&)\u001b[m\u001b[K’ is deprecated: precomputeWordVectors is being deprecated. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     precomputeWordVectors(*wordVectors_\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/fasttext.cc:534:6:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " void \u001b[01;36m\u001b[KFastText\u001b[m\u001b[K::precomputeWordVectors(DenseMatrix& wordVectors) {\n",
            "      \u001b[01;36m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "c++ -pthread -std=c++0x -march=native -O3 -funroll-loops -DNDEBUG args.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n",
            "Processing /content/fastText-0.9.1\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (2.4.3)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (41.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.1) (1.17.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2385275 sha256=77e44d36431b42f0dfd081f89092dcf439c07aff3323f20c359d7e1aba621ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/fa/7a/c31efe7a2a5a79ef4cb20d04cb48814badc1e7712d4845fbbb\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BJRNMImFwG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02ae9be6-ab0e-4552-9b8a-79eea816c3a7"
      },
      "source": [
        "sentences_text = [word for word in df_atheism['body'].values]\n",
        "sentences_text[:3]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['argu', 'deep', 'human', 'except', 'thing', 'defianc', 'idea'],\n",
              " ['differ',\n",
              "  'harri',\n",
              "  'potter',\n",
              "  'bibl',\n",
              "  'coupl',\n",
              "  'billion',\n",
              "  'peopl',\n",
              "  'believ',\n",
              "  'harri',\n",
              "  'potter',\n",
              "  'fiction',\n",
              "  '23',\n",
              "  'billion',\n",
              "  'peopl',\n",
              "  'believ',\n",
              "  'bibl',\n",
              "  'truth',\n",
              "  'figur',\n",
              "  'actual',\n",
              "  'peopl',\n",
              "  'believ',\n",
              "  'import',\n",
              "  'instanc',\n",
              "  'exist',\n",
              "  'justif',\n",
              "  'bibl',\n",
              "  'believ',\n",
              "  'jesus',\n",
              "  'die',\n",
              "  'fact',\n",
              "  'jewish',\n",
              "  'pharise',\n",
              "  'save',\n",
              "  'life',\n",
              "  'book',\n",
              "  'liter',\n",
              "  'saysi',\n",
              "  'sure',\n",
              "  'feel',\n",
              "  'mind',\n",
              "  'fuck',\n",
              "  'have',\n",
              "  'accept',\n",
              "  'truth',\n",
              "  'jew',\n",
              "  'christian',\n",
              "  'muslim',\n",
              "  'atheist',\n",
              "  'regardless',\n",
              "  'fact',\n",
              "  'liter',\n",
              "  'bibl',\n",
              "  'say',\n",
              "  'stop',\n",
              "  'believ',\n",
              "  'lie',\n",
              "  'spread',\n",
              "  'christian',\n",
              "  ' ',\n",
              "  'ps',\n",
              "  ' ',\n",
              "  '60',\n",
              "  'popul',\n",
              "  'believ',\n",
              "  'jesus',\n",
              "  'way',\n",
              "  'democrat',\n",
              "  'major',\n",
              "  'planet',\n",
              "  'figur',\n",
              "  'accord',\n",
              "  'sourc',\n",
              "  'believ',\n",
              "  'obvious',\n",
              "  'import',\n",
              "  'doubt',\n",
              "  'need',\n",
              "  'quot',\n",
              "  'sourc',\n",
              "  'critic',\n",
              "  'atheist'],\n",
              " ['explain', 'argument']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i41RmMQQg0He",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55e4be3d-4150-4813-f3c9-2857c698f99c"
      },
      "source": [
        "sentences_text[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['argu', 'deep', 'human', 'except', 'thing', 'defianc', 'idea']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pECmqOePEMUp",
        "colab_type": "text"
      },
      "source": [
        "Now we can train our classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S-VocU0FKY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4d5fb6cd-1778-497e-f212-7bcce3efdcc5"
      },
      "source": [
        "%%time\n",
        "model_fasttext_atheism = FastText(sentences_text, size=200, window=5, min_count=5, workers=3,sg=1)\n",
        "# model_fasttext_atheism.save(\"model_fasttext_atheism\")\n",
        "# !gsutil cp /content/model_fasttext_atheism gs://reddit_models/"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27min 30s, sys: 1.73 s, total: 27min 32s\n",
            "Wall time: 9min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-nH2VGAeni_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04073b0a-c7ba-46aa-ec0f-60d29f96b5fd"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fastText-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iENnvk0VewRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "62a51e61-5431-43f1-bfbd-6394ea92b60c"
      },
      "source": [
        "!gsutil cp /content/fastText-0.9.1/model_fasttext_atheism gs://reddit_models/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/fastText-0.9.1/model_fasttext_atheism [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/189.0 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "\\\n",
            "Operation completed over 1 objects/189.0 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixZEFXusgex9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22109d61-49e1-4e65-d2ce-f8c47f68aa7a"
      },
      "source": [
        "model_fasttext_atheism.wv.vectors.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42016, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuUmR-Jrafzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "9af5002c-3ccd-460c-973c-1acdfc49910f"
      },
      "source": [
        "model_fasttext_atheism.wv.most_similar(\"pope\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('popei', 0.7969644069671631),\n",
              " ('franci', 0.7832726836204529),\n",
              " ('gtpope', 0.7675614953041077),\n",
              " ('popey', 0.7129794359207153),\n",
              " ('vatican', 0.704525351524353),\n",
              " ('papal', 0.650409460067749),\n",
              " ('papaci', 0.646502673625946),\n",
              " ('jp2', 0.6357030868530273),\n",
              " ('benedict', 0.6325761079788208),\n",
              " ('ratzing', 0.6322858333587646)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpRaWxACa40R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "93220c85-eef0-4198-f8db-fb34a34439b0"
      },
      "source": [
        "model_fasttext_atheism.wv.doesnt_match(\"pope\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'o'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytk8ym8ha4gF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "03a15d48-469d-4e2d-9c9c-fcf1a26d66c7"
      },
      "source": [
        "model_fasttext_atheism.wv.similarity(\"pope\",\"hairdryer\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16275942"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJnDN_Ubf4e2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "924e8e5f-7813-46ea-d914-fb5e16232a02"
      },
      "source": [
        "model_fasttext_atheism.wv.similarity(\"pope\",\"priest\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51841784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY805TOaXKXp",
        "colab_type": "text"
      },
      "source": [
        "### Word2vec - atheism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAuu-5zgXJRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NceCdwEcXRVi",
        "colab_type": "code",
        "outputId": "a5c3d8dd-5a5e-40d1-df67-f765135cd77b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sentences_w2v_atheism = [word for word in df_atheism['body'].values]\n",
        "sentences_w2v_atheism[:3]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['argu', 'deep', 'human', 'except', 'thing', 'defianc', 'idea'],\n",
              " ['differ',\n",
              "  'harri',\n",
              "  'potter',\n",
              "  'bibl',\n",
              "  'coupl',\n",
              "  'billion',\n",
              "  'peopl',\n",
              "  'believ',\n",
              "  'harri',\n",
              "  'potter',\n",
              "  'fiction',\n",
              "  '23',\n",
              "  'billion',\n",
              "  'peopl',\n",
              "  'believ',\n",
              "  'bibl',\n",
              "  'truth',\n",
              "  'figur',\n",
              "  'actual',\n",
              "  'peopl',\n",
              "  'believ',\n",
              "  'import',\n",
              "  'instanc',\n",
              "  'exist',\n",
              "  'justif',\n",
              "  'bibl',\n",
              "  'believ',\n",
              "  'jesus',\n",
              "  'die',\n",
              "  'fact',\n",
              "  'jewish',\n",
              "  'pharise',\n",
              "  'save',\n",
              "  'life',\n",
              "  'book',\n",
              "  'liter',\n",
              "  'saysi',\n",
              "  'sure',\n",
              "  'feel',\n",
              "  'mind',\n",
              "  'fuck',\n",
              "  'have',\n",
              "  'accept',\n",
              "  'truth',\n",
              "  'jew',\n",
              "  'christian',\n",
              "  'muslim',\n",
              "  'atheist',\n",
              "  'regardless',\n",
              "  'fact',\n",
              "  'liter',\n",
              "  'bibl',\n",
              "  'say',\n",
              "  'stop',\n",
              "  'believ',\n",
              "  'lie',\n",
              "  'spread',\n",
              "  'christian',\n",
              "  ' ',\n",
              "  'ps',\n",
              "  ' ',\n",
              "  '60',\n",
              "  'popul',\n",
              "  'believ',\n",
              "  'jesus',\n",
              "  'way',\n",
              "  'democrat',\n",
              "  'major',\n",
              "  'planet',\n",
              "  'figur',\n",
              "  'accord',\n",
              "  'sourc',\n",
              "  'believ',\n",
              "  'obvious',\n",
              "  'import',\n",
              "  'doubt',\n",
              "  'need',\n",
              "  'quot',\n",
              "  'sourc',\n",
              "  'critic',\n",
              "  'atheist'],\n",
              " ['explain', 'argument']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiV7rxH7XgwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4b71d5d3-49ba-4a6d-f914-bfbdb57e8363"
      },
      "source": [
        "%%time\n",
        "\n",
        "modelWV_atheism = Word2Vec(sentences_w2v_atheism, workers = 3, min_count=5, window = 10, size = EMBEDDING_DIM)\n",
        "modelWV_atheism.train(sentences_w2v_atheism, total_examples=len(sentences_w2v_atheism), epochs=50)\n",
        "# modelWV_atheism.save(\"model_word2vec\")\n",
        "# !gsutil cp /content/model_word2vec gs://reddit_models/"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 52min 19s, sys: 8.85 s, total: 52min 27s\n",
            "Wall time: 18min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfQP3zK8gJ9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25d6a8dd-3a7e-49ce-fad2-b3665166d7fb"
      },
      "source": [
        "modelWV_atheism.wv.vectors.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42016, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNRxtzwnYWjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "4715a321-1641-4ed2-f52d-770e9118e337"
      },
      "source": [
        "modelWV_atheism.wv.most_similar(\"pope\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('franci', 0.7146515250205994),\n",
              " ('vatican', 0.6533546447753906),\n",
              " ('ratzing', 0.5700125694274902),\n",
              " ('gtpope', 0.561491072177887),\n",
              " ('papaci', 0.5403313636779785),\n",
              " ('papal', 0.526868462562561),\n",
              " ('vigano', 0.5170674324035645),\n",
              " ('jp2', 0.514457643032074),\n",
              " ('cardin', 0.5137941837310791),\n",
              " ('benedict', 0.5112627744674683)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-cE-dKfgAed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "851f8dda-79f9-4ca9-f5fc-4f2b3768cd15"
      },
      "source": [
        "modelWV_atheism.wv.similarity(\"pope\",\"hairdryer\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02832523"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSJ3tFv3gAT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7241a98a-9f8c-477e-bc3e-b399aa64276d"
      },
      "source": [
        "modelWV_atheism.wv.similarity(\"pope\",\"priest\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4967405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p442UJhMijeS",
        "colab_type": "text"
      },
      "source": [
        "## Modelling - atheism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JFYkRxwjO-z",
        "colab_type": "text"
      },
      "source": [
        "The splitted df into train, validation and test is `df_atheism_split`. Let's using it for train the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfA6NZ9IsAYJ",
        "colab_type": "text"
      },
      "source": [
        "#### XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J3wk-P6glTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "273d2168-06bd-4511-e1a6-28db8c68c095"
      },
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorize\", TfidfVectorizer(ngram_range=(1,2), lowercase=False, preprocessor=' '.join)),\n",
        "    (\"classifier\", XGBClassifier())\n",
        "])\n",
        "\n",
        "model.fit(df_atheism_split['X_train'], df_atheism_split['y_train'])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorize',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=False, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=<built-in method join of str object at 0x7f44a9f4f538>,\n",
              "                                 smooth_idf=True, stop_words=None,\n",
              "                                 strip...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=1, nthread=None,\n",
              "                               objective='binary:logistic', random_state=0,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuEdirhMglOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(df_atheism_split['X_val'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otz9WqromYh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b334e35-faf6-4356-b20d-41bab0d0a14c"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn0wXC1Izf-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "b6eae0d9-24af-40bc-8286-29aad22ba04e"
      },
      "source": [
        "print ('accuracy ', accuracy_score(df_atheism_split['y_val'], prediction))\n",
        "print ('precision ', precision_score(df_atheism_split['y_val'], prediction))\n",
        "print (classification_report(df_atheism_split['y_val'], prediction))\n",
        "print (confusion_matrix(df_atheism_split['y_val'], prediction))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy  1.0\n",
            "precision  0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00    116040\n",
            "\n",
            "    accuracy                           1.00    116040\n",
            "   macro avg       1.00      1.00      1.00    116040\n",
            "weighted avg       1.00      1.00      1.00    116040\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[116040]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RC802sEp6yE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f5578d6-766f-4bd6-c61a-0eccbf1fad50"
      },
      "source": [
        "cross_val_score(model,  df_atheism_split['X_val'], df_atheism_split['y_val'], cv=5,scoring=\"accuracy\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEkDQGLOr9la",
        "colab_type": "text"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_LMci-imYeH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f9ddbf4b-e2a4-447b-edc2-6e645ebc7f4a"
      },
      "source": [
        "%%time\n",
        "\n",
        "SVC_model = Pipeline([\n",
        "                (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), lowercase=False, preprocessor=' '.join)),\n",
        "                (\"clf\", OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
        "            ])\n",
        "\n",
        "SVC_model.fit(df_atheism_split['X_train'], df_atheism_split['y_train'])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 47.3 s, sys: 575 ms, total: 47.9 s\n",
            "Wall time: 47.8 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQVo91VPmYZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0f09e3f-62c4-49b3-bc74-b5c3e6223ef4"
      },
      "source": [
        "prediction_SVC = SVC_model.predict(df_atheism_split['X_val'])\n",
        "prediction_SVC"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAW8S4gz0z-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "a07d5bfc-8359-4c94-8967-0e3a5f6d83a5"
      },
      "source": [
        "print ('accuracy ', accuracy_score(df_atheism_split['y_val'], prediction_SVC))\n",
        "print ('precision ', precision_score(df_atheism_split['y_val'], prediction_SVC))\n",
        "print (classification_report(df_atheism_split['y_val'], prediction_SVC))\n",
        "print (confusion_matrix(df_atheism_split['y_val'], prediction_SVC))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy  1.0\n",
            "precision  0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00    116040\n",
            "\n",
            "    accuracy                           1.00    116040\n",
            "   macro avg       1.00      1.00      1.00    116040\n",
            "weighted avg       1.00      1.00      1.00    116040\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[116040]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLe6ENQmuG4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f30c6b1c-f630-4f9f-9df7-e79ec3ca11c5"
      },
      "source": [
        "cross_val_score(SVC_model, df_atheism_split['X_val'], df_atheism_split['y_val'], cv=5,scoring=\"accuracy\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6BHJWDbulfK",
        "colab_type": "text"
      },
      "source": [
        "#### NB with fasttext - WIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82XdhIzOhov8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "72a1ff7c-e2a6-4d17-af4e-b8be4b21eece"
      },
      "source": [
        "NB_pipeline = Pipeline([\n",
        "                (\"fasttext\", model_fasttext_atheism),\n",
        "                (\"clf\", OneVsRestClassifier(MultinomialNB(\n",
        "                    fit_prior=True, class_prior=None))),\n",
        "            ])\n",
        "                \n",
        "NB_pipeline.fit(df_atheism_split['X_train'], df_atheism_split['y_train'])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-abee964aed46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;34m\"fasttext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fasttext_atheism\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 (\"clf\", OneVsRestClassifier(MultinomialNB(\n\u001b[0;32m----> 4\u001b[0;31m                     fit_prior=True, class_prior=None))),\n\u001b[0m\u001b[1;32m      5\u001b[0m             ])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                                 \u001b[0;34m\"or be the string 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                 \"'%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'FastText(vocab=42016, size=200, alpha=0.025)' (type <class 'gensim.models.fasttext.FastText'>) doesn't"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUQA7i4Zxeiz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "10ec977b-1c90-4bc5-8039-7ebdd33037ed"
      },
      "source": [
        "svc = Pipeline([(\"count_vectorizer\", vectorizer), (\"OneVSRest svc linear\", OneVsRestClassifier(SVC(kernel='linear')))])\n",
        "svc_tfidf = Pipeline([(\"tfidf_vectorizer\", tf_vectorizer), (\"OneVSRest svc linear\", OneVsRestClassifier(SVC(kernel='linear')))])\n",
        "#randomF = Pipeline([(\"count_vectorizer\", vectorizer), (\"RandomForestClassifier\", RandomForestClassifier(n_estimators=100))])\n",
        "#randomF_tfidf = Pipeline([(\"tfidf_vectorizer\", tf_vectorizer), (\"RandomForestClassifier\", RandomForestClassifier(n_estimators=100))])\n",
        "#extraT = Pipeline([(\"count_vectorizer\", vectorizer), (\"ExtraTreesClassifier\", ExtraTreesClassifier(n_estimators=100))])\n",
        "#extraT_tfidf = Pipeline([(\"tfidf_vectorizer\", tf_vectorizer), (\"ExtraTreesClassifier\", ExtraTreesClassifier(n_estimators=100))])\n",
        "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v)), (\"word2vec extra trees\", ExtraTreesClassifier(n_estimators=100))])\n",
        "etree_w2v_tfidf = Pipeline([(\"tfidf word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)), (\"tfidf word2vec extra trees\", ExtraTreesClassifier(n_estimators=100))])\n",
        "\n",
        "\n",
        "all_models = [\n",
        "    (\"svc\", svc),\n",
        "    (\"svc_tfidf\", svc_tfidf),\n",
        "    #(\"randomF\", randomF), \n",
        "    #(\"randomF_tfidf\", randomF_tfidf),\n",
        "    #(\"extraT\", extraT), \n",
        "    #(\"extraT_tfidf\", extraT_tfidf),\n",
        "    (\"etree_w2v\", etree_w2v), \n",
        "    (\"etree_w2v_tfidf\", etree_w2v_tfidf)\n",
        "]\n",
        "scores = sorted([(name, cross_val_score(model, df['text'], df['product'], cv=kfold).mean()) \n",
        "             for name, model in all_models], \n",
        "            key=lambda args: -(args[1]))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-d8652cb3d55f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count_vectorizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"OneVSRest svc linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msvc_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tfidf_vectorizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_vectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"OneVSRest svc linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#randomF = Pipeline([(\"count_vectorizer\", vectorizer), (\"RandomForestClassifier\", RandomForestClassifier(n_estimators=100))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#randomF_tfidf = Pipeline([(\"tfidf_vectorizer\", tf_vectorizer), (\"RandomForestClassifier\", RandomForestClassifier(n_estimators=100))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#extraT = Pipeline([(\"count_vectorizer\", vectorizer), (\"ExtraTreesClassifier\", ExtraTreesClassifier(n_estimators=100))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD28pBHCafpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_9vDnjEafu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6CISyVRafxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}