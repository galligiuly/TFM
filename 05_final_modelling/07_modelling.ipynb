{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl https://sdk.cloud.google.com | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?code_challenge=V5tsDrUrEHNUwpkgiFRh9HZEz2iFC2YhArEAgp432GA&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
      "\n",
      "\n",
      "\u001b[1;33mWARNING:\u001b[0m `gcloud auth login` no longer writes application default credentials.\n",
      "If you need to use ADC, see:\n",
      "  gcloud auth application-default --help\n",
      "\n",
      "You are now logged in as [galli.giuly@gmail.com].\n",
      "Your current project is [None].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n"
     ]
    }
   ],
   "source": [
    "# connecting to google cloud\n",
    "\n",
    "!/Users/giuliagalli/google-cloud-sdk/bin/gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the volume of my dataframe, I had to pick a subreddit (atheism) and testing vectorizacion and test on it.\n",
    "Now I've seen that it's woriking fine, I can do it to all the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/giuliagalli/Documents/GitHub/TFM/05_final_modelling\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['aww', 'nba', 'movies', 'todayilearned', 'IAmA', 'Fitness', 'worldnews', 'technology', 'europe', 'politics', 'atheism','science', 'funny', 'gaming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_aww.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_nba.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_movies.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_todayilearned.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_IAmA.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_Fitness.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_worldnews.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_technology.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_europe.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_politics.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_atheism.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_science.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_funny.pkl downloaded\n",
      "/bin/sh: /Users/giuliagalli/Documents/GitHub/TFM/05_modelling: is a directory\n",
      "comments_posts_gaming.pkl downloaded\n"
     ]
    }
   ],
   "source": [
    "for subreddit in subreddits:\n",
    "    !/Users/giuliagalli/Documents/GitHub/TFM/05_modelling gsutil cp gs://reddit_final_results/comments_posts_{subreddit}.pkl .\n",
    "    print(\"comments_posts_\" + subreddit + \".pkl downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_aww.pkl...\n",
      "/ [1 files][ 63.8 MiB/ 63.8 MiB]    6.9 MiB/s                                   \n",
      "Operation completed over 1 objects/63.8 MiB.                                     \n",
      "comments_posts_aww.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_nba.pkl...\n",
      "| [1 files][ 88.3 MiB/ 88.3 MiB]    5.5 MiB/s                                   \n",
      "Operation completed over 1 objects/88.3 MiB.                                     \n",
      "comments_posts_nba.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_movies.pkl...\n",
      "/ [1 files][103.2 MiB/103.2 MiB]    6.2 MiB/s                                   \n",
      "Operation completed over 1 objects/103.2 MiB.                                    \n",
      "comments_posts_movies.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_todayilearned.pkl...\n",
      "| [1 files][101.1 MiB/101.1 MiB]    6.7 MiB/s                                   \n",
      "Operation completed over 1 objects/101.1 MiB.                                    \n",
      "comments_posts_todayilearned.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_IAmA.pkl...\n",
      "- [1 files][132.8 MiB/132.8 MiB]    8.0 MiB/s                                   \n",
      "Operation completed over 1 objects/132.8 MiB.                                    \n",
      "comments_posts_IAmA.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_Fitness.pkl...\n",
      "\\ [1 files][144.0 MiB/144.0 MiB]    7.8 MiB/s                                   \n",
      "Operation completed over 1 objects/144.0 MiB.                                    \n",
      "comments_posts_Fitness.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_worldnews.pkl...\n",
      "| [1 files][134.8 MiB/134.8 MiB]    6.5 MiB/s                                   \n",
      "Operation completed over 1 objects/134.8 MiB.                                    \n",
      "comments_posts_worldnews.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_technology.pkl...\n",
      "| [1 files][136.2 MiB/136.2 MiB]    7.1 MiB/s                                   \n",
      "Operation completed over 1 objects/136.2 MiB.                                    \n",
      "comments_posts_technology.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_europe.pkl...\n",
      "\\ [1 files][128.4 MiB/128.4 MiB]    7.4 MiB/s                                   \n",
      "Operation completed over 1 objects/128.4 MiB.                                    \n",
      "comments_posts_europe.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_politics.pkl...\n",
      "- [1 files][118.7 MiB/118.7 MiB]    8.2 MiB/s                                   \n",
      "Operation completed over 1 objects/118.7 MiB.                                    \n",
      "comments_posts_politics.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_atheism.pkl...\n",
      "| [1 files][144.0 MiB/144.0 MiB]    6.9 MiB/s                                   \n",
      "Operation completed over 1 objects/144.0 MiB.                                    \n",
      "comments_posts_atheism.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_science.pkl...\n",
      "| [1 files][147.5 MiB/147.5 MiB]    6.3 MiB/s                                   \n",
      "Operation completed over 1 objects/147.5 MiB.                                    \n",
      "comments_posts_science.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_funny.pkl...\n",
      "- [1 files][ 69.3 MiB/ 69.3 MiB]    5.4 MiB/s                                   \n",
      "Operation completed over 1 objects/69.3 MiB.                                     \n",
      "comments_posts_funny.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_gaming.pkl...\n",
      "- [1 files][ 79.4 MiB/ 79.4 MiB]    6.0 MiB/s                                   \n",
      "Operation completed over 1 objects/79.4 MiB.                                     \n",
      "comments_posts_gaming.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 32s, sys: 3min 53s, total: 6min 26s\n",
      "Wall time: 14min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_df = pd.DataFrame(columns = [\"subreddit\", \"body\", \"subreddit_id\"])\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    !/Users/giuliagalli/google-cloud-sdk/bin/gsutil cp gs://reddit_final_results/comments_posts_{subreddit}.pkl .\n",
    "    print(\"comments_posts_\" + subreddit + \".pkl downloaded\")\n",
    "    \n",
    "    df = pd.read_pickle(\"comments_posts_\" + subreddit + \".pkl\")\n",
    "\n",
    "    model_df = pd.concat([model_df, df], ignore_index=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10833350, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             [doubl, multipl, sub, approach, good, ya, mate]\n",
       "1           [2nd, meatbal, serious, chunki, english, bulld...\n",
       "2                                                   [thought]\n",
       "3                                       [friend, eat, friend]\n",
       "4                           [mayb, doctor, wait, heart, room]\n",
       "                                  ...                        \n",
       "10833344    [bethesda, fix, fallout, 76, start, say, huge,...\n",
       "10833345    [ssbu, dlc, request, play, mario, rpg, want, g...\n",
       "10833346    [got, 50, steam, gift, card, christma, recomme...\n",
       "10833347    [motorstorm, arctic, edg, best, seri, control,...\n",
       "10833348    [question, nt, decid, read, deadredempt, 2, ki...\n",
       "Name: body, Length: 10833349, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df['body'].iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df['body']\n",
    "y = model_df['subreddit_id']\n",
    "\n",
    "# Definint a fucntion that slit the dataset into three subsets: train, val and test\n",
    "def train_dev_test_split(X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42, stratify=y_val)\n",
    "    return dict(X_train=X_train, \n",
    "                X_val=X_val, \n",
    "                X_test=X_test, \n",
    "                y_train=y_train, \n",
    "                y_val=y_val, \n",
    "                y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 2 µs, total: 13 µs\n",
      "Wall time: 24.1 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "model_df_split = train_dev_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:57] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_xgbc = Pipeline([\n",
    "    (\"vectorize\", TfidfVectorizer(ngram_range=(1,2), lowercase=False, preprocessor=' '.join)),\n",
    "    (\"classifier\", XGBClassifier())\n",
    "])\n",
    "\n",
    "model_xgbc.fit(model_df_split['X_train'], model_df_split['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_xgbc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
