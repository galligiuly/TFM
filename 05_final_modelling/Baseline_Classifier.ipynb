{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?code_challenge=FvKaxJodnRh9SR9h2g3ENbSDX7XGr_mT7c-sbz5HwY4&prompt=select_account&code_challenge_method=S256&access_type=offline&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth\n",
      "\n",
      "\n",
      "\u001b[1;33mWARNING:\u001b[0m `gcloud auth login` no longer writes application default credentials.\n",
      "If you need to use ADC, see:\n",
      "  gcloud auth application-default --help\n",
      "\n",
      "You are now logged in as [galli.giuly@gmail.com].\n",
      "Your current project is [reddit-master].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project reddit-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "import plotly.figure_factory as ff\n",
    "import logging\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://reddit_final_results/comments_posts_2018.csv\r\n",
      "gs://reddit_final_results/comments_posts_2018.zip\r\n",
      "gs://reddit_final_results/comments_posts_2018_V2.csv\r\n",
      "gs://reddit_final_results/comments_posts_2018_V2.zip\r\n",
      "gs://reddit_final_results/comments_posts_Fitness.pkl\r\n",
      "gs://reddit_final_results/comments_posts_IAmA.pkl\r\n",
      "gs://reddit_final_results/comments_posts_atheism.pkl\r\n",
      "gs://reddit_final_results/comments_posts_aww.pkl\r\n",
      "gs://reddit_final_results/comments_posts_europe.pkl\r\n",
      "gs://reddit_final_results/comments_posts_funny.pkl\r\n",
      "gs://reddit_final_results/comments_posts_gaming.pkl\r\n",
      "gs://reddit_final_results/comments_posts_movies.pkl\r\n",
      "gs://reddit_final_results/comments_posts_nba.pkl\r\n",
      "gs://reddit_final_results/comments_posts_politics.pkl\r\n",
      "gs://reddit_final_results/comments_posts_science.pkl\r\n",
      "gs://reddit_final_results/comments_posts_technology.pkl\r\n",
      "gs://reddit_final_results/comments_posts_todayilearned.pkl\r\n",
      "gs://reddit_final_results/comments_posts_tokenized.csv\r\n",
      "gs://reddit_final_results/comments_posts_tokenized.zip\r\n",
      "gs://reddit_final_results/comments_posts_tokenized_V2.csv\r\n",
      "gs://reddit_final_results/comments_posts_tokenized_V2.zip\r\n",
      "gs://reddit_final_results/comments_posts_tokenized_df.pkl\r\n",
      "gs://reddit_final_results/comments_posts_tokenized_df_gzip.pkl\r\n",
      "gs://reddit_final_results/comments_posts_worldnews.pkl\r\n",
      "gs://reddit_final_results/red_comments_posts.csv\r\n",
      "gs://reddit_final_results/red_comments_posts_tokenized.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://reddit_final_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['aww', 'nba', 'movies', 'todayilearned', 'IAmA', 'Fitness', 'worldnews', 'technology', 'europe', 'politics', 'atheism','science', 'funny', 'gaming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_aww.pkl...\n",
      "/ [1 files][ 63.8 MiB/ 63.8 MiB]                                                \n",
      "Operation completed over 1 objects/63.8 MiB.                                     \n",
      "comments_posts_aww.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_nba.pkl...\n",
      "- [1 files][ 88.3 MiB/ 88.3 MiB]    6.9 MiB/s                                   \n",
      "Operation completed over 1 objects/88.3 MiB.                                     \n",
      "comments_posts_nba.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_movies.pkl...\n",
      "\\ [1 files][103.2 MiB/103.2 MiB]    5.7 MiB/s                                   \n",
      "Operation completed over 1 objects/103.2 MiB.                                    \n",
      "comments_posts_movies.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_todayilearned.pkl...\n",
      "/ [1 files][101.1 MiB/101.1 MiB]    7.3 MiB/s                                   \n",
      "Operation completed over 1 objects/101.1 MiB.                                    \n",
      "comments_posts_todayilearned.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_IAmA.pkl...\n",
      "- [1 files][132.8 MiB/132.8 MiB]    7.3 MiB/s                                   \n",
      "Operation completed over 1 objects/132.8 MiB.                                    \n",
      "comments_posts_IAmA.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_Fitness.pkl...\n",
      "\\ [1 files][144.0 MiB/144.0 MiB]    6.8 MiB/s                                   \n",
      "Operation completed over 1 objects/144.0 MiB.                                    \n",
      "comments_posts_Fitness.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_worldnews.pkl...\n",
      "\\ [1 files][134.8 MiB/134.8 MiB]    6.3 MiB/s                                   \n",
      "Operation completed over 1 objects/134.8 MiB.                                    \n",
      "comments_posts_worldnews.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_technology.pkl...\n",
      "- [1 files][136.2 MiB/136.2 MiB]    6.8 MiB/s                                   \n",
      "Operation completed over 1 objects/136.2 MiB.                                    \n",
      "comments_posts_technology.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_europe.pkl...\n",
      "/ [1 files][128.4 MiB/128.4 MiB]    7.6 MiB/s                                   \n",
      "Operation completed over 1 objects/128.4 MiB.                                    \n",
      "comments_posts_europe.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_politics.pkl...\n",
      "- [1 files][118.7 MiB/118.7 MiB]    7.1 MiB/s                                   \n",
      "Operation completed over 1 objects/118.7 MiB.                                    \n",
      "comments_posts_politics.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_atheism.pkl...\n",
      "\\ [1 files][144.0 MiB/144.0 MiB]    8.6 MiB/s                                   \n",
      "Operation completed over 1 objects/144.0 MiB.                                    \n",
      "comments_posts_atheism.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_science.pkl...\n",
      "| [1 files][147.5 MiB/147.5 MiB]    5.8 MiB/s                                   \n",
      "Operation completed over 1 objects/147.5 MiB.                                    \n",
      "comments_posts_science.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_funny.pkl...\n",
      "\\ [1 files][ 69.3 MiB/ 69.3 MiB]    4.5 MiB/s                                   \n",
      "Operation completed over 1 objects/69.3 MiB.                                     \n",
      "comments_posts_funny.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://reddit_final_results/comments_posts_gaming.pkl...\n",
      "/ [1 files][ 79.4 MiB/ 79.4 MiB]                                                \n",
      "Operation completed over 1 objects/79.4 MiB.                                     \n",
      "comments_posts_gaming.pkl downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 2min 5s, total: 4min 8s\n",
      "Wall time: 9min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_baseline = pd.DataFrame(columns = [\"subreddit\", \"body\", \"subreddit_id\"])\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    !gsutil cp gs://reddit_final_results/comments_posts_{subreddit}.pkl .\n",
    "    print(\"comments_posts_\" + subreddit + \".pkl downloaded\")\n",
    "\n",
    "    df = pd.read_pickle(\"comments_posts_\" + subreddit + \".pkl\")\n",
    "\n",
    "    model_baseline = pd.concat([model_baseline, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_baseline['body']\n",
    "y = model_baseline['subreddit_id']\n",
    "\n",
    "# Definint a fucntion that slit the dataset into three subsets: train, val and test\n",
    "def train_dev_test_split(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    return dict(X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                y_train=y_train.astype('int'),\n",
    "                y_test=y_test.astype('int'))\n",
    "\n",
    "model_baseline_split = train_dev_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "dummy.fit(model_baseline_split[\"X_train\"], model_baseline_split[\"y_train\"])\n",
    "\n",
    "y_pred = dummy.predict(model_baseline_split[\"X_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07130635183638179\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, model_baseline_split[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba de Multi Layer Perceptron con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
